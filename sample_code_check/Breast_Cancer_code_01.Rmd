---
title: "Breast_Cancer_code_01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

## Breast_cancer analysis

### Step 0 : usage library
설치 안된 라이브러리의 경우 설치 필요
```{r}
library(PerformanceAnalytics)
library(psych)
library(ggplot2)
library(GGally)
library(factoextra)
library(corrplot)
library(gridExtra)
library(caret)
library(C50)
library(highcharter)
library(rpart)
library(RWeka)
library(e1071)
library(randomForest)
library(party)
library(class)
library(ada)
library(gbm)
library(reshape2)
library(dplyr)
library(stringr)
library(knitr)
```

<br>

### Step 1: Intro & Purpose
* 이 커널에서 많은 분류 방법을 사용
* 각 함수를 더 잘 이해하기 위해 함수 바로 위에 라이브러리를 작성

<br>

### Step 2: Data Importing & Cleaning & Inspecting
#### 2-1) Import dataset
breast_cancer_data means 'wisconsin breast cancer data'
```{r}
breast_cancer_data <- read.csv("./data/breast_cancer.csv", header=T, stringsAsFactors=F)

tail(breast_cancer_data)
```

#### 2-2) Remove NULL Data
```{r}
breast_cancer_data$X <- NULL
```

#### 2-3) Reshape the datasets
```{r}
# breast_cancer_data 첫 번째 열을 제외한 모든 열로 구성
breast_cancer_data <- breast_cancer_data[,-1]

# breast_cancer_data$diagnosis의 각 값이 "B"인지 확인하고, 
#"B"이면 "Benign"으로, 그렇지 않으면 "Malignant"으로 변환
breast_cancer_data$diagnosis <- factor(ifelse(breast_cancer_data$diagnosis=="B","Benign","Malignant"))
```

#### 2-4) Inspect the datasets {.tabset}
##### structure
```{r}
str(breast_cancer_data)
```
<br>

### 변수 설명 (32개)

##### id 및 diagnosis (2개)(0:1)
* id (ID 번호): 각 환자의 고유 식별 번호
* diagnosis (진단): 유방 조직의 진단 결과 (M = malignant(악성), B = benign(양성))

참고 내용

진단 (Diagnosis)

양성 (Benign): 양성 종양은 일반적으로 비교적 덜 위험하며, 주변 조직에 침범 X

악성 (Malignant): 악성 종양은 주변 조직으로의 침입이나 전이 가능성이 있으며, 더 높은 위험을 내포

##### mean (10개)(2:11)
* radius_mean (반경 평균): 중심에서 둘레까지의 거리의 평균
* texture_mean (질감 평균): gray-scale 값의 표준 편차
* perimeter_mean (둘레 평균): 핵 종양의 평균 크기
* area_mean (면적 평균): 핵 종양의 면적의 평균
* smoothness_mean (매끄러움 평균): 반지름 길이의 지역 변동의 평균
* compactness_mean (조그만함 평균): 둘레^2 / 면적 - 1.0의 평균
* concavity_mean (오목함 평균): 등고선의 오목한 부분의 심각도의 평균
* concave points_mean (오목한 지점 평균): 등고선의 오목한 부분의 수의 평균
* symmetry_mean (대칭성 평균): 대칭성의 평균
* fractal_dimension_mean (프랙탈 차원 평균): "coastline approximation(해안선 근사치)" - 1의 평균

##### se (10개)(12:21)
* radius_se (반경 표준 오차): 중심에서 둘레까지의 거리의 평균의 표준 오차
* texture_se (질감 표준 오차): gray-scale 값의 표준 편차의 표준 오차
* perimeter_se (둘레 표준 오차): 핵 종양의 평균 크기의 표준 오차
* area_se (면적 표준 오차): 핵 종양의 면적의 표준 오차
* smoothness_se (매끄러움 표준 오차): 반지름 길이의 지역 변동의 표준 오차
* compactness_se (조그만함 표준 오차): 둘레^2 / 면적 - 1.0의 표준 오차
* concavity_se (오목함 표준 오차): 등고선의 오목한 부분의 심각도의 표준 오차
* concave points_se (오목한 지점 표준 오차): 등고선의 오목한 부분의 수의 표준 오차
* symmetry_se (대칭성 표준 오차): 대칭성의 표준 오차
* fractal_dimension_se (프랙탈 차원 표준 오차): "coastline approximation" - 1의 표준 오차

##### worst (10개)(22:31)
* radius_worst (반경 최악): 중심에서 둘레까지의 거리의 평균의 최대값
* texture_worst (질감 최악): gray-scale 값의 표준 편차의 최대값
* perimeter_worst (둘레 최악): 핵 종양의 평균 크기의 최대값
* area_worst (면적 최악): 핵 종양의 면적의 최대값
* smoothness_worst (매끄러움 최악): 반지름 길이의 지역 변동의 최대값
* compactness_worst (조그만함 최악): 둘레^2 / 면적 - 1.0의 최대값
* concavity_worst (오목함 최악): 등고선의 오목한 부분의 심각도의 최대값
* concave points_worst (오목한 지점 최악): 등고선의 오목한 부분의 수의 최대값
* symmetry_worst (대칭성 최악): 대칭성의 최대값
* fractal_dimension_worst (프랙탈 차원 최악): "coastline approximation" - 1의 최대값

<br>

##### summary
```{r}
summary(breast_cancer_data)
```

##### tail
```{r}
tail(breast_cancer_data)
```

<br>

## Step 3: Analyze the Correlation between variables
#### 3-1) Correlation between each variables {.tabset}
correalation plot를 그리는 여러 가지 방법

각 데이터에 서로 다른 함수(mean, se, worst)를 적용해봤음

##### Mean

```{r}
# suppressWarnings() : 경고메세지 무시
suppressWarnings({
  library(PerformanceAnalytics)
  
  # 상관 행렬을 시각화
  chart.Correlation(breast_cancer_data[,c(2:11)],histogram=TRUE, col="grey10", pch=1, main="Cancer Mean")
})
```

##### SE
* 피어슨 상관계수란? (일반적으로 "상관 계수"라고 언급할 때, 피어슨 상관 계수를 의미)
* 두 변수의 선형 상관 관계를 계량화한 수치
* 결과값은 -1 ~ 1 사이의 값,
* 양의 상관 관계가 있을수록 1에 가깝고, 음의 상관 관계가 있을수록 -1에 가까움
* 또한, 상관 관계가 없을수록 0에 가까움

```{r}
library(psych)

pairs.panels(breast_cancer_data[,c(12:21)], method="pearson",
             hist.col = "#1fbbfa", density=TRUE, ellipses=TRUE, show.points = TRUE,
             pch=1, lm=TRUE, cex.cor=1, smoother=F, stars = T, main="Cancer SE")
```

##### Worst
* "Cancer Worst"에 대한 산점도 행렬을 생성
```{r}
library(ggplot2)
library(GGally)

ggpairs(breast_cancer_data[,c(22:31)],) + 
  theme_bw() + 
  labs(title="Cancer Worst") +
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=13))
```


#### 3-2) See the relation between each variables (diagnosis included) {.tabset}
combined data보다 diagnosis가 포함된 플롯을 보는 것이 훨씬 더 중요하다고 생각[3-1]

##### Mean
```{r}
ggpairs(breast_cancer_data[,c(2:11,1)], aes(color=diagnosis, alpha=0.75), lower=list(continuous="smooth")) +
  theme_bw() + 
  labs(title="Cancer Mean") +
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```

##### SE
```{r}
ggpairs(breast_cancer_data[,c(12:21,1)], aes(color=diagnosis, alpha=0.75), lower=list(continuous="smooth"))+ theme_bw()+
labs(title="Cancer SE")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```

##### Worst
```{r}
ggpairs(breast_cancer_data[,c(22:31,1)], aes(color=diagnosis, alpha=0.75), lower=list(continuous="smooth"))+ theme_bw()+
labs(title="Cancer Worst")+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```

#### 3-3) See the ggcorr plot {.tabset}
By ggcorr, we can see the correlation value more directly than above graph.

##### Mean
* ggcorr 함수를 사용하여 "Cancer Mean"에 대한 상관 행렬을 시각화
```{r}
ggcorr(breast_cancer_data[,c(2:11)], name = "corr", label = TRUE) +
  theme(legend.position="none") +
  labs(title="Cancer Mean") +
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))

```


##### SE
* ggcorr 함수를 사용하여 "Cancer SE"에 대한 상관 행렬을 시각화
```{r}
ggcorr(breast_cancer_data[,c(12:21)], name = "corr", label = TRUE) +
  theme(legend.position="none") +
  labs(title="Cancer SE") +
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```


##### Worst
* ggcorr 함수를 사용하여 "Cancer Worst"에 대한 상관 행렬을 시각화
```{r}
ggcorr(breast_cancer_data[,c(22:31)], name = "corr", label = TRUE) +
  theme(legend.position="none") +
  labs(title="Cancer Worst") +
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```

---


### Step 4: Principal Component Analysis (PCA)

변수가 너무 많으면 아래와 같은 문제가 발생할 수 있습니다.

- 컴퓨터 처리량 증가

- 너무 복잡한 시각화 문제

- 분석에 영향을 주지 않는 변수를 포함시켜 효율성을 떨어뜨림

- 데이터 해석을 어렵게 만든다


위의 ggcorr 플롯을 보면 [3-3] 상관관계 값이 높다는 것은 변수 간에 "다중 공선성"이 있음을 의미합니다.

-> 상관관계가 높은 변수를 줄여 하나의 주요 구성요소를 모델 개발에 사용합니다.

**주성분의 수를 결정할 때,
누적 기여율을 사용
또는 screeplot을 사용하고 고유값 곡선이 수평으로 놓여 있는 주성분의 이전 단계를 사용합니다.

PCA는 스케일 차이로 인한 데이터 왜곡을 방지하기 위해 표준화된 데이터를 사용합니다.

```{r}
library(factoextra)

breast_cancer_pca <- transform(breast_cancer_data)	
tail(breast_cancer_pca)
```

#### 4-1) Summary {.tabset}
PCA 결과 Cumulative Proportion(누적비율)율이 85% 이상이면 number of principal components(주성분의 수)로 판단할 수 있다.

* View Point(시점) : Cumulative Proportion

For example, if cumulative proportion of PC4 is 88.7, it means **the sum of proportion of PC1~PC4** is 88.7


##### All
The cumulative proportion from PC1 to PC6 is about 88.7%. (85%이상)

It means that PC1~PC6 can explain 88.7% of the whole data.

* Standard Deviation (표준 편차) 
* 각 주성분의 표준 편차
* 표준 편차는 데이터가 얼마나 퍼져 있는지를 측정하는 지표이며, 주성분들은 표준 편차의 내림차순으로 정렬되어 있음
* 주성분들의 표준 편차가 클수록 해당 주성분이 데이터의 변동성을 더 많이 설명

* Proportion of Variance (분산의 비율)
* 각 주성분이 전체 데이터의 분산을 얼마나 설명하는지의 비율
* 높은 비율일수록 해당 주성분이 중요한 구조를 나타냅니다. 누적된 비율은 해당 주성분까지의 누적 설명 비율을 나타냅니다.

```{r}
all_pca <- prcomp(breast_cancer_pca[,-1], cor=TRUE, scale = TRUE)
summary(all_pca)
```

##### Mean
The cumulative proportion from PC1 to PC3 is about 88.7%. (above 85%)
```{r}
mean_pca <- prcomp(breast_cancer_pca[,c(2:11)], scale = TRUE)
summary(mean_pca)
```

##### SE
The cumulative proportion from PC1 to PC4 is about 86.7%. (above 85%)
```{r}
se_pca <- prcomp(breast_cancer_pca[,c(12:21)], scale = TRUE)
summary(se_pca)
```

##### Worst
The cumulative proportion from PC1 to PC3 is about 85.8%. (above 85%)
```{r}
worst_pca <- prcomp(breast_cancer_pca[,c(22:31)], scale = TRUE)
summary(worst_pca)
```


#### 4-2) Screeplot {.tabset}
principal components(주성분)으로 설명되는 The percentage of variability(변동성의 백분율)은 screeplot를 통해 확인할수 있음

=> View Point : principal components where the line lies.

##### All
Line lies at point PC6
```{r}
fviz_eig(all_pca, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "Cancer All Variances - PCA",
         x = "Principal Components", y = "% of variances")
```

##### Mean
Line lies at point PC4
```{r}
fviz_eig(mean_pca, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "Cancer Mean Variances - PCA",
         x = "Principal Components", y = "% of variances")
```

##### SE
Line lies at point PC4
```{r}
fviz_eig(se_pca, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "Cancer SE Variances - PCA",
         x = "Principal Components", y = "% of variances")
```

##### Worst
Line lies at point PC4
```{r}
fviz_eig(worst_pca, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10) + 
  labs(title = "Cancer Worst Variances - PCA",
         x = "Principal Components", y = "% of variances")
```

#### 4-3) Get PCA Variables {.tabset}
##### All
###### Get PCA Variables
```{r}
all_var <- get_pca_var(all_pca)
all_var
```

* $coord (Coordinates)
설명: 변수들의 주성분 축에 대한 좌표입니다.
의미: 각 변수가 주성분 축에서 어떤 위치에 있는지를 나타냅니다.

* $cor (Correlations)
설명: 변수와 주성분 간의 상관 관계를 나타냅니다.
의미: 주성분이 어떤 변수들과 관련이 있는지, 각 주성분이 어떤 변수들과 어떤 방향으로 연관되어 있는지를 보여줍니다.

* $cos2 (Cos2)
설명: 변수들의 코사인 제곱 값입니다. 변수가 주성분에 얼마나 설명력을 가지고 있는지를 나타냅니다.
의미: 코사인 제곱 값이 높을수록 변수가 해당 주성분에 대해 설명력이 큽니다.

* $contrib (Contributions)
설명: 변수들의 기여도를 나타냅니다.
의미: 각 변수가 전체 주성분의 형성에 얼마나 기여했는지를 나타내며, 값이 클수록 해당 변수가 주성분 형성에 큰 역할을 했다고 볼 수 있습니다.


###### Quality of representation of PCA
* Correlation between variables and PCA
* corrplot 함수는 상관 행렬을 시각적으로 나타내는 데 사용되는 함수
* corrplot 함수는 변수들 간의 코사인 제곱 값을 시각적으로 나타내는 플롯을 생성합니다. 이 플롯은 변수들이 각 주성분에 얼마나 설명력을 가지고 있는지를 보여줄 것입니다. 높은 값은 해당 변수가 주성분에 대해 큰 설명력을 가지고 있음을 나타냅니다.

```{r}
library("corrplot")
corrplot(all_var$cos2, is.corr=FALSE)
```

###### Contributions of variables to PCA
To highlight the most contributing variables for each components
```{r}
corrplot(all_var$contrib, is.corr=FALSE)	
```

###### Contributions of variables to PC1 & PC2
```{r}
library(gridExtra)
# 주성분 분석 결과에서 주어진 주성분에 대한 변수 기여도를 시각화
p1 <- fviz_contrib(all_pca, choice="var", axes=1, fill="pink", color="grey", top=10)
p2 <- fviz_contrib(all_pca, choice="var", axes=2, fill="skyblue", color="grey", top=10)

# 그래프를 2x1 레이아웃으로 배열
grid.arrange(p1,p2,ncol=2)
```


##### Mean
###### Get PCA Variables
```{r}
mean_var <- get_pca_var(mean_pca)
mean_var
```

###### Quality of representation of PCA
Correlation between variables and PCA
```{r}
library("corrplot")
corrplot(mean_var$cos2, is.corr=FALSE)
```

###### Contributions of variables to PCA
To highlight the most contributing variables for each components
```{r}
corrplot(mean_var$contrib, is.corr=FALSE)	
```

###### Contributions of variables to PC1 & PC2
```{r}
library(gridExtra)
p1 <- fviz_contrib(mean_pca, choice="var", axes=1, fill="pink", color="grey", top=10)
p2 <- fviz_contrib(mean_pca, choice="var", axes=2, fill="skyblue", color="grey", top=10)
grid.arrange(p1,p2,ncol=2)
```

##### SE
###### Get PCA Variables
```{r}
se_var <- get_pca_var(se_pca)
se_var
```

###### Quality of representation of PCA
Correlation between variables and PCA
```{r}
library("corrplot")
corrplot(se_var$cos2, is.corr=FALSE)
```

###### Contributions of variables to PCA
To highlight the most contributing variables for each components
```{r}
corrplot(se_var$contrib, is.corr=FALSE)	
```

###### Contributions of variables to PC1 & PC2
```{r}
library(gridExtra)
p1 <- fviz_contrib(se_pca, choice="var", axes=1, fill="pink", color="grey", top=10)
p2 <- fviz_contrib(se_pca, choice="var", axes=2, fill="skyblue", color="grey", top=10)
grid.arrange(p1,p2,ncol=2)
```

##### Worst
###### Get PCA Variables
```{r}
worst_var <- get_pca_var(worst_pca)
worst_var
```

###### Quality of representation of PCA
Correlation between variables and PCA
```{r}
library("corrplot")
corrplot(worst_var$cos2, is.corr=FALSE)
```

###### Contributions of variables to PCA
To highlight the most contributing variables for each components
```{r}
corrplot(worst_var$contrib, is.corr=FALSE)	
```

###### Contributions of variables to PC1 & PC2
```{r}
library(gridExtra)
p1 <- fviz_contrib(worst_pca, choice="var", axes=1, fill="pink", color="grey", top=10)
p2 <- fviz_contrib(worst_pca, choice="var", axes=2, fill="skyblue", color="grey", top=10)
grid.arrange(p1,p2,ncol=2)
```


#### 4-4) See the plot - color variables by groups {.tabset}
value centers : 위에서 선택한 optimal principal component 값을 넣음

##### All
optimal PC value : PC1~PC6
```{r}
# 시드 설정
set.seed(218)

# k-means 군집화 수행
# 데이터 all_var$coord
# 군집 수는 6개, 초기 중심점은 25번 재설정하여 최적의 군집을 찾음
res.all <- kmeans(all_var$coord, centers = 6, nstart = 25)
grp <- as.factor(res.all$cluster)

# 주성분 분석 결과 시각화
fviz_pca_var(all_pca, col.var = grp, 
             palette = "jco",
             legend.title = "Cluster")
```

##### Mean
optimal PC value : PC1~PC3
```{r}
# 시드 설정
set.seed(218)

# k-means 군집화 수행
res.mean <- kmeans(mean_var$coord, centers = 3, nstart = 25)
grp <- as.factor(res.mean$cluster)

# 주성분 분석 결과 시각화
fviz_pca_var(mean_pca, col.var = grp, 
             palette = "jco",
             legend.title = "Cluster")
```

##### SE
optimal PC value : PC1~PC4
```{r}
# 시드 설정
set.seed(218)

# k-means 군집화 수행
res.se <- kmeans(se_var$coord, centers = 4, nstart = 25)
grp <- as.factor(res.se$cluster)

# 주성분 분석 결과 시각화
fviz_pca_var(se_pca, col.var = grp, 
             palette = "jco",
             legend.title = "Cluster")
```

##### Worst
optimal PC value : PC1~PC3
```{r}
# 시드 설정
set.seed(218)

# k-means 군집화 수행
res.worst <- kmeans(worst_var$coord, centers = 3, nstart = 25)
grp <- as.factor(res.worst$cluster)

# 주성분 분석 결과 시각화
fviz_pca_var(worst_pca, col.var = grp, 
             palette = "jco",
             legend.title = "Cluster")
```


#### 4-5) See the Biplot {.tabset}
```{r}
library("factoextra")
```

##### All

* all_pca
주성분 분석의 결과 객체

* col.ind = breast_cancer_data$diagnosis
데이터 포인트를 색상으로 구분할 기준 변수입니다. 여기서는 진단(diagnosis) 정보를 기준으로 데이터 포인트를 색상으로 나타냅니다.

* col="black"
변수들의 색상을 지정합니다. 여기서는 검은색으로 설정되었습니다.

* palette = "jco"
데이터 포인트의 다양한 클래스를 표현하기 위한 색상 팔레트입니다. "jco"는 팔레트의 이름으로, 다양한 색상을 제공합니다.

* geom = "point"
데이터 포인트를 점으로 표현합니다.

* repel=TRUE
데이터 포인트 간의 겹침을 방지하기 위해 repel 기능을 사용합니다.

* legend.title="Diagnosis"
범례의 제목을 "Diagnosis"로 설정합니다.

* addEllipses = TRUE
주성분 분석의 결과에 따라 클래스 간의 타원을 추가하여 시각적으로 나타냅니다.

```{r}
fviz_pca_biplot(all_pca, col.ind = breast_cancer_data$diagnosis, col="black",
                palette = "jco", geom = "point", repel=TRUE,
                legend.title="Diagnosis", addEllipses = TRUE)
```

##### Mean
```{r}
fviz_pca_biplot(mean_pca, col.ind = breast_cancer_data$diagnosis, col="black",
                palette = "jco", geom = "point", repel=TRUE,
                legend.title="Diagnosis", addEllipses = TRUE)
```

##### SE
```{r}
fviz_pca_biplot(se_pca, col.ind = breast_cancer_data$diagnosis, col="black",
                palette = "jco", geom = "point", repel=TRUE,
                legend.title="Diagnosis", addEllipses = TRUE)
```

##### Worst
```{r}
fviz_pca_biplot(worst_pca, col.ind = breast_cancer_data$diagnosis, col="black",
                palette = "jco", geom = "point", repel=TRUE,
                legend.title="Diagnosis", addEllipses = TRUE)
```


---


### Step 5: 모든 ML 방법을 적용하고 서로 비교하여 가장 적합한 것을 선택합니다.
#### 5-1) Make test & train dataset for testing classification ML methods
Shuffle the wbcd data(100%) & Make train dataset(70%), test dataset(30%)

* 분류 ML 방법 테스트를 위한 테스트 및 학습 데이터 세트 만들기
* breast_cancer_data 데이터 섞기(100%) & train 데이터세트 만들기(70%), test 데이터세트(30%)

```{r}
nrows <- NROW(breast_cancer_data)

# 난수 생성을 위한 시드 고정
set.seed(218)       

# 데이터 인덱스를 섞은 후 70%를 학습 데이터로 선택
index <- sample(1:nrows, 0.7 * nrows)   

train <- breast_cancer_data[index,]   # 학습 데이터: 선택된 70%의 데이터
test <- breast_cancer_data[-index,]   # 테스트 데이터: 나머지 30%의 데이터

```


#### 5-2) Check the proportion of diagnosis (Benign / Malignant) {.tabset}
##### train
```{r}
prop.table(table(train$diagnosis))
```

##### test
```{r}
prop.table(table(test$diagnosis))
```


#### 5-3) Apply every ML methods(that I know) to data {.tabset}
* "Caret"은 Classification And REgression Training의 약자로, 모델 훈련과 관련된 다양한 기능을 제공하는 유용한 도구 모음
```{r}
library(caret)
```

##### C5.0
```{r}
library(C50)
# 의사 결정 트리 기반의 분류 알고리즘
# C5.0 알고리즘은 데이터의 속성들 중에서 최적의 속성을 선택하여 트리를 성장시키고, 이를 통해 주어진 데이터를 특정 클래스 또는 범주로 분류

# C5.0 알고리즘을 사용하여 학습된 모델
learn_c50 <- C5.0(train[,-1],train$diagnosis)

# 학습된 모델을 사용하여 테스트 데이터셋에서의 예측값
pre_c50 <- predict(learn_c50, test[,-1])

# 혼동 행렬(Confusion Matrix)을 생성
cm_c50 <- confusionMatrix(pre_c50, test$diagnosis)
cm_c50
```

* Confusion Matrix:
True Positive (TP): 108 (실제 Malignant, 예측 Malignant)
True Negative (TN): 56 (실제 Benign, 예측 Benign)
False Positive (FP): 4 (실제 Benign, 예측 Malignant)
False Negative (FN): 3 (실제 Malignant, 예측 Benign)

* 정확도 (Accuracy): 95.91%
전체 예측 중 올바르게 예측한 비율

* 95% 신뢰 구간 (95% Confidence Interval):
정확도의 신뢰 구간은 91.75%에서 98.34% 사이.

* No Information Rate: 64.91%
가장 많은 클래스 (여기서는 Benign)를 예측하는 단순한 모델의 정확도.

* Kappa 통계량: 90.98%
모델의 성능을 평가하는 데 사용되는 통계량. 0%에서 100% 사이의 값을 가지며, 100%에 가까울수록 모델이 좋은 성능을 가지고 있다는 것을 의미.

* Sensitivity (민감도): 97.30%
실제 Malignant 중에서 정확하게 예측한 비율.

* Specificity (특이도): 93.33%
실제 Benign 중에서 정확하게 예측한 비율.

* Positive Predictive Value (양성 예측 값): 96.43%
모델이 양성으로 예측한 경우 중에서 실제로 양성인 비율.

* Negative Predictive Value (음성 예측 값): 94.92%
모델이 음성으로 예측한 경우 중에서 실제로 음성인 비율.

* Prevalence (유병률): 64.91%
전체 데이터 중 양성 클래스(Benign)의 비율.

* Detection Rate: 63.16%
모델이 실제 양성을 얼마나 잘 감지했는지를 나타냄.

* Detection Prevalence: 65.50%
모델이 양성이라고 예측한 전체 데이터 중 양성 클래스(Benign)의 비율.

* Balanced Accuracy: 95.32%
불균형한 클래스 크기를 고려하여 계산된 정확도.

* 'Positive' Class: Benign
양성 클래스로 설정된 클래스.


##### C5.0 - Tune
###### Choose 'trials' which shows best predict performance in C5.0
```{r}
# C5.0 알고리즘의 성능을 trials 매개변수를 다양하게 변화시켜가며 평가하고 최적의 trials 횟수를 찾는 코드

# 빈 numeric 벡터 acc_test를 생성하여 테스트 정확도를 저장할 예정
acc_test <- numeric()

# 각각 혼동 행렬과 전체 정확도를 저장할 변수
accuracy1 <- NULL
accuracy2 <- NULL

# 1부터 50까지 trials 횟수에 대해 반복
for (i in 1:50) {
  # C5.0 모델 학습. trials 매개변수를 i로 설정
  learn_imp_c50 <- C5.0(train[, -1], train$diagnosis, trials = i)
  
  # 테스트 데이터에 대한 예측 수행
  p_c50 <- predict(learn_imp_c50, test[, -1])
  
  # 혼동 행렬 계산
  accuracy1 <- confusionMatrix(p_c50, test$diagnosis)
  
  # 전체 정확도를 accuracy2에 저장
  accuracy2[i] <- accuracy1$overall[1]
}

# 결과를 data.frame으로 저장
acc <- data.frame(t = seq(1, 50), cnt = accuracy2)

# 최적의 trials 횟수 및 정확도에 대한 부제 생성
opt_t <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of trials is", opt_t$t, "(accuracy :", opt_t$cnt,") in C5.0")

# Highcharter를 사용하여 정확도에 대한 라인 차트 생성
library(highcharter)
hchart(acc, 'line', hcaes(t, cnt)) %>%
  hc_title(text = "Accuracy With Varying Trials (C5.0)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Trials")) %>%
  hc_yAxis(title = list(text = "Accuracy"))


```

###### Apply optimal trials to show best predict performance in C5.0
```{r}		
learn_imp_c50 <- C5.0(train[,-1],train$diagnosis,trials=opt_t$t)	
pre_imp_c50 <- predict(learn_imp_c50, test[,-1])
cm_imp_c50 <- confusionMatrix(pre_imp_c50, test$diagnosis)
cm_imp_c50
```

##### rpart
```{r}
library(rpart)

# rpart 함수를 사용하여 의사결정 나무 모델을 학습
learn_rp <- rpart(diagnosis~.,data=train,control=rpart.control(minsplit=2))

# 테스트 데이터에 대한 예측
pre_rp <- predict(learn_rp, test[,-1], type="class")

# 혼동 행렬 생성
cm_rp  <- confusionMatrix(pre_rp, test$diagnosis)	

# 결과 출력
cm_rp
```



##### Prune
```{r}
# 의사결정 나무 모델 학습
learn_rp <- rpart(diagnosis ~ ., data = train, control = rpart.control(minsplit = 2))

# 학습된 모델을 최적 복잡성 매개변수로 가지치기
learn_pru <- prune(learn_rp, cp = learn_rp$cptable[which.min(learn_rp$cptable[, "xerror"]), "CP"])

# 테스트 데이터에 대한 예측 수행
pre_pru <- predict(learn_pru, test[, -1], type = "class")

# 가지친 모델로 생성된 혼동 행렬 확인
cm_pru <- confusionMatrix(pre_pru, test$diagnosis)
cm_pru

```


##### OneR
```{r}
library("RWeka")

# RWeka 라이브러리에서 One Rule 모델 학습
learn_1r <- OneR(diagnosis ~ ., data = train)

# 학습된 One Rule 모델을 사용하여 테스트 데이터에 대한 예측 수행
pre_1r <- predict(learn_1r, test[, -1])

# 혼동 행렬 생성
cm_1r <- confusionMatrix(pre_1r, test$diagnosis)
cm_1r

```


##### JRip
```{r}
# RWeka 라이브러리에서 JRip 모델 학습
learn_jrip <- JRip(diagnosis ~ ., data = train)

# 학습된 JRip 모델을 사용하여 테스트 데이터에 대한 예측 수행
pre_jrip <- predict(learn_jrip, test[, -1])

# 혼동 행렬 생성
cm_jrip <- confusionMatrix(pre_jrip, test$diagnosis)
cm_jrip

```


##### naiveBayes
###### naiveBayes에서 가장 좋은 예측 성능을 보이는 'laplace'를 선택
* 이는 "laplace" 함수가 naiveBayes의 성능 예측에 효과적이지 않음을 보여줌
* 따라서 튜닝에 laplace 옵션을 사용하지 않아도 됨
```{r}
library(e1071)

# e1071 라이브러리에서 naiveBayes 모델 학습 및 정확도 평가
acc_test <- numeric()
accuracy1 <- NULL; accuracy2 <- NULL

# Laplace smoothing 파라미터를 1부터 30까지 변화시키면서 정확도 평가
for (i in 1:30) {
    learn_imp_nb <- naiveBayes(train[, -1], train$diagnosis, laplace = i)    
    p_nb <- predict(learn_imp_nb, test[, -1]) 
    accuracy1 <- confusionMatrix(p_nb, test$diagnosis)
    accuracy2[i] <- accuracy1$overall[1]
}

# 결과를 데이터프레임으로 저장
acc <- data.frame(l = seq(1, 30), cnt = accuracy2)

# 최적 Laplace 값 및 정확도 확인
opt_l <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of Laplace is", opt_l$l, "(accuracy:", opt_l$cnt, ") in naiveBayes")

# Highcharter를 사용하여 정확도 변화를 시각화
library(highcharter)
hchart(acc, 'line', hcaes(l, cnt)) %>%
  hc_title(text = "Accuracy With Varying Laplace (naiveBayes)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Laplace")) %>%
  hc_yAxis(title = list(text = "Accuracy"))

```

###### naiveBayes without laplace
```{r}
# e1071 라이브러리에서 naiveBayes 모델 학습
learn_nb <- naiveBayes(train[, -1], train$diagnosis)

# 학습된 모델을 사용하여 테스트 데이터에 대한 예측 수행
pre_nb <- predict(learn_nb, test[, -1])

# 혼동 행렬 생성
cm_nb <- confusionMatrix(pre_nb, test$diagnosis)
cm_nb

```

##### randomForest
```{r}
library(randomForest)

# randomForest 모델 학습
learn_rf <- randomForest(diagnosis ~ ., data=train, ntree=500, proximity=T, importance=T)

# 학습된 모델을 사용하여 테스트 데이터에 대한 예측 수행
pre_rf <- predict(learn_rf, test[, -1])

# 혼동 행렬 생성
cm_rf <- confusionMatrix(pre_rf, test$diagnosis)
cm_rf

```
```{r}
plot(learn_rf, main="Random Forest (Error Rate vs. Number of Trees)")
```

###### Prediction Plot
* randomForest 모델의 margin을 시각화하는데 사용
* margin은 결정 경계와 각 클래스에 대한 거리를 나타냄

```{r}
plot(margin(learn_rf,test$diagnosis))
```

###### Variance Importance Plot
- MeanDecreaseAccuracy : radius_worst > concave.points_worst > area_worst > perimeter_worst

정확도 향상을 위한 중요한 매개변수는 "MeanDecreaseAccuracy"에 의해 결정됩니다.

- MeanDecreaseGini : perimeter_worst > radius_worst > area_worst > concave.points_worst

노드 불순물을 개선하기 위한 중요한 매개변수는 "MeanDecreaseGini"에 의해 결정됩니다

```{r}
varImpPlot(learn_rf)
```


##### ctree
```{r}
library(party)

# 의사결정 나무 학습
learn_ct <- ctree(diagnosis ~ ., data = train, controls = ctree_control(maxdepth = 2))

# 테스트 데이터에 대한 예측 수행
pre_ct <- predict(learn_ct, test[, -1])

# 혼동 행렬 계산
cm_ct <- confusionMatrix(pre_ct, test$diagnosis)
cm_ct

```

##### KNN - Tune
###### Choose 'k' which shows best predict performance in KNN


```{r}
## k-최근접 이웃 (KNN) 알고리즘을 사용하여 다양한 이웃의 수(k)에 대한 정확도를 평가하는 과정
library(class)

# 정확도를 저장할 벡터 초기화
acc_test <- numeric() 

# 다양한 이웃의 수(k)에 대해 정확도를 평가
for (i in 1:30) {
    # knn 함수를 사용하여 KNN 알고리즘을 적용하고 정확도를 계산
    predict <- knn(train = train[, -1], test = test[, -1], cl = train[, 1], k = i, prob = TRUE)
    acc_test <- c(acc_test, mean(predict == test[, 1]))
}

# 정확도 결과를 데이터프레임으로 변환
acc <- data.frame(k = seq(1, 30), cnt = acc_test)

# 최적의 k 값 찾기
opt_k <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of k is", opt_k$k, "(accuracy :", opt_k$cnt, ") in KNN")

# highcharter 패키지를 사용하여 정확도 그래프 생성
library(highcharter)
hchart(acc, 'line', hcaes(k, cnt)) %>%
  hc_title(text = "Accuracy With Varying K (KNN)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Neighbors(k)")) %>%
  hc_yAxis(title = list(text = "Accuracy"))

```

###### Apply optimal K to show best predict performance in KNN
```{r}
# 최적의 k 값을 사용하여 KNN 알고리즘 적용
pre_knn <- knn(train = train[, -1], test = test[, -1], cl = train[, 1], k = opt_k$k, prob = TRUE)

# 혼동 행렬 생성
cm_knn <- confusionMatrix(pre_knn, test$diagnosis)
cm_knn

```


##### K-Means
###### Make KMEANS predict function
* orgin predict function는 kmeans를 지원하지 않기 때문에 kmeans 방법을 사용하여 예측하는 함수를 만들어야 합니다.
```{r}
predict.kmeans <- function(newdata, object) {
    # K-means 모델에서 중심점 가져오기
    centers <- object$centers
    n_centers <- nrow(centers)
    
    # 중심점과 새로운 데이터 간의 거리 행렬 계산
    dist_mat <- as.matrix(dist(rbind(centers, newdata)))
    
    # 중심점과의 거리 행렬에서 새로운 데이터에 대한 거리 정보 추출
    dist_mat <- dist_mat[-seq(n_centers), seq(n_centers)]
    
    # 거리가 가장 작은 군집 선택하여 예측
    max.col(-dist_mat)
}

```

###### apply kmeans
인자가 2개(benign, malignant)뿐이므로 중심을 2에 적용해야 합니다.

```{r}
library(caret)

# K-means 모델을 학습 (군집 수: 2)
learn_kmeans <- kmeans(train[,-1], centers=2)

# 예측 함수를 사용하여 테스트 데이터에 대한 군집 예측 수행
pre_kmeans <- predict.kmeans(test[,-1], learn_kmeans)

# 군집 예측 결과를 "Benign" 또는 "Malignant"로 변환
pre_kmeans <- as.factor(ifelse(pre_kmeans == 1, "Benign", "Malignant"))

# 혼동 행렬 계산
cm_kmeans <- confusionMatrix(pre_kmeans, test$diagnosis)

```

###### plot
```{r}
library(factoextra)

# K-means 모델의 군집 결과를 "Benign" 또는 "Malignant"로 변환
learn_kmeans$cluster <- ifelse(learn_kmeans$cluster == 1, "Benign", "Malignant")

# fviz_cluster 함수를 사용하여 군집화 결과를 시각화
fviz_cluster(learn_kmeans, data = train[,-1])
```


##### GBM
```{r}
library(gbm)

# GBM 모델 학습
test_gbm <- gbm(diagnosis ~ ., data = train, distribution = "gaussian", n.trees = 10000,
                shrinkage = 0.01, interaction.depth = 4, bag.fraction = 0.5, train.fraction = 0.5,
                n.minobsinnode = 10, cv.folds = 3, keep.data = TRUE, verbose = FALSE, n.cores = 1)

# 최적의 트리 수 계산
best.iter <- gbm.perf(test_gbm, method = "cv", plot.it = FALSE)

# 모델 튜닝을 위한 제어 매개변수 설정
fitControl = trainControl(method = "cv", number = 5, returnResamp = "all")

# train 함수를 사용하여 GBM 모델 학습
learn_gbm = train(diagnosis ~ ., data = train, method = "gbm", distribution = "bernoulli",
                  trControl = fitControl, verbose = FALSE,
                  tuneGrid = data.frame(.n.trees = best.iter, .shrinkage = 0.01, .interaction.depth = 1, .n.minobsinnode = 1))

# 테스트 데이터에 대한 예측
pre_gbm <- predict(learn_gbm, test[,-1])

# 혼동 행렬 계산
cm_gbm <- confusionMatrix(pre_gbm, test$diagnosis)
cm_gbm
```


##### adaBoost
```{r}
library(rpart)
library(ada)

# rpart 모델의 제어 매개변수 설정
control <- rpart.control(cp = -1, maxdepth = 14, maxcompete = 1, xval = 0)

# AdaBoost 모델 학습
learn_ada <- ada(diagnosis ~ ., data = train, test.x = train[,-1], test.y = train[,1],
                 type = "gentle", control = control, iter = 70)

# 테스트 데이터에 대한 예측
pre_ada <- predict(learn_ada, test[,-1])

# 혼동 행렬 계산
cm_ada <- confusionMatrix(pre_ada, test$diagnosis)
cm_ada
```


##### SVM
```{r}
# SVM 모델 학습
learn_svm <- svm(diagnosis ~ ., data = train)

# 테스트 데이터에 대한 예측
pre_svm <- predict(learn_svm, test[,-1])

# 혼동 행렬 계산
cm_svm <- confusionMatrix(pre_svm, test$diagnosis)
cm_svm
```


##### SVM - Tune
###### Choose 'gamma, cost' which shows best predict performance in SVM
```{r}
# 각각의 cost와 gamma에 대한 조합을 생성
gamma <- seq(0, 0.1, 0.005)
cost <- 2^(0:5)
parms <- expand.grid(cost = cost, gamma = gamma)    ## 231

# 정확도를 저장할 변수 초기화
acc_test <- numeric()
accuracy1 <- NULL; accuracy2 <- NULL

# 각 조합에 대해 SVM 모델 학습 및 정확도 계산
for (i in 1:NROW(parms)) {
    learn_svm <- svm(diagnosis ~ ., data = train, gamma = parms$gamma[i], cost = parms$cost[i])
    pre_svm <- predict(learn_svm, test[,-1])
    accuracy1 <- confusionMatrix(pre_svm, test$diagnosis)
    accuracy2[i] <- accuracy1$overall[1]
}

# 결과를 데이터 프레임으로 저장
acc <- data.frame(p = seq(1, NROW(parms)), cnt = accuracy2)

# 최적의 하이퍼파라미터 및 정확도 정보
opt_p <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of parameters is", opt_p$p, "(accuracy :", opt_p$cnt, ") in SVM")

# 그래프 생성
library(highcharter)
hchart(acc, 'line', hcaes(p, cnt)) %>%
  hc_title(text = "Accuracy With Varying Parameters (SVM)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Parameters")) %>%
  hc_yAxis(title = list(text = "Accuracy"))

```

###### Apply optimal parameters(gamma, cost) to show best predict performance in SVM
```{r}
# 최적의 하이퍼파라미터를 사용하여 SVM 모델 학습
learn_imp_svm <- svm(diagnosis ~ ., data = train, cost = parms$cost[opt_p$p], gamma = parms$gamma[opt_p$p])

# 테스트 데이터에 대한 예측 수행
pre_imp_svm <- predict(learn_imp_svm, test[,-1])

# 혼동 행렬 계산
cm_imp_svm <- confusionMatrix(pre_imp_svm, test$diagnosis)
cm_imp_svm

```


#### 5-4) Visualize to compare the accuracy of all methods
```{r}
# 색상 정의
col <- c("#ed3b3b", "#0099ff")

# 그래프 구성 설정
par(mfrow=c(3,5))

# 각 모델별 혼동 행렬 시각화
fourfoldplot(cm_c50$table, color = col, conf.level = 0, margin = 1, main=paste("C5.0 (",round(cm_c50$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_imp_c50$table, color = col, conf.level = 0, margin = 1, main=paste("Tune C5.0 (",round(cm_imp_c50$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_rp$table, color = col, conf.level = 0, margin = 1, main=paste("RPart (",round(cm_rp$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_pru$table, color = col, conf.level = 0, margin = 1, main=paste("Prune (",round(cm_pru$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_1r$table, color = col, conf.level = 0, margin = 1, main=paste("OneR (",round(cm_1r$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_jrip$table, color = col, conf.level = 0, margin = 1, main=paste("JRip (",round(cm_jrip$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_ct$table, color = col, conf.level = 0, margin = 1, main=paste("CTree (",round(cm_ct$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_nb$table, color = col, conf.level = 0, margin = 1, main=paste("NaiveBayes (",round(cm_nb$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_knn$table, color = col, conf.level = 0, margin = 1, main=paste("Tune KNN (",round(cm_knn$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_kmeans$table, color = col, conf.level = 0, margin = 1, main=paste("KMeans (",round(cm_kmeans$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_rf$table, color = col, conf.level = 0, margin = 1, main=paste("RandomForest (",round(cm_rf$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_gbm$table, color = col, conf.level = 0, margin = 1, main=paste("GBM (",round(cm_gbm$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_ada$table, color = col, conf.level = 0, margin = 1, main=paste("AdaBoost (",round(cm_ada$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_svm$table, color = col, conf.level = 0, margin = 1, main=paste("SVM (",round(cm_svm$overall[1]*100),"%)",sep=""))
fourfoldplot(cm_imp_svm$table, color = col, conf.level = 0, margin = 1, main=paste("Tune SVM (",round(cm_imp_svm$overall[1]*100),"%)",sep=""))
```



#### 5-5) Select a best prediction model according to high accuracy
```{r}
# 각 모델의 정확도를 벡터로 저장
opt_predict <- c(
  cm_c50$overall[1], cm_imp_c50$overall[1], cm_rp$overall[1],
  cm_pru$overall[1], cm_1r$overall[1], cm_jrip$overall[1],
  cm_ct$overall[1], cm_nb$overall[1], cm_knn$overall[1],
  cm_kmeans$overall[1], cm_rf$overall[1], cm_gbm$overall[1],
  cm_ada$overall[1], cm_svm$overall[1], cm_imp_svm$overall[1]
)

# 모델명을 지정
names(opt_predict) <- c(
  "c50", "imp_c50", "rpart", "prune", "1r", "jrip", "ctree",
  "nb", "knn", "kmeans", "rf", "gbm", "ada", "svm", "imp_svm"
)

# 가장 높은 정확도를 보이는 모델 식별
best_predict_model <- subset(opt_predict, opt_predict == max(opt_predict))

```


### Step 1: Prepare Patient data for testing function 
If you want to make your own new data, 
make sure your data format is same as below.

#### 6-1) Import patient data {.tabset}
```{r}
patient <- read.csv("./data/breast_cancer.csv", header=T, stringsAsFactors=F)
patient$X <- NULL
```

##### Malignant patient(악성 환자)   	
```{r}
M <- patient[19,]   	    	## 19th patient
M[,c(1,2)]			            ## Malignant
```

##### Benign patient(양성 환자)
```{r}
B <- patient[20,]           ## 20th patient          
B[,c(1,2)]			            ## Benign
```

#### 6-2) Delete diagnosis column for testing
```{r}
M$diagnosis <- NULL
B$diagnosis <- NULL
```

---


### Step 7: 환자의 암 진단 예측 Function
#### 7-1) 환자 진단 Function
가장 좋은 예측 모델로 평가되었으므로 'Improve SVM Algorithm'을 기본으로 사용하세요.

```{r}
# 텍스트 출력용 함수
cancer_diagnosis_predict_p <- function(new, method = learn_imp_svm) {
  # 모델을 사용하여 새로운 데이터에 대한 예측 수행
  new_pre <- predict(method, new[, -1])
  new_res <- as.character(new_pre)
  # 환자 ID와 예측 결과를 텍스트로 반환
  return(paste("환자 ID: ", new[, 1], "  =>  결과: ", new_res, sep = ""))
}

# 제출용 함수
cancer_diagnosis_predict_s <- function(new, method = learn_imp_svm) {
  # 모델을 사용하여 새로운 데이터에 대한 예측 수행
  new_pre <- predict(method, new[, -1])
  new_res <- as.character(new_pre)
  # 예측 결과를 문자열로 반환
  return(new_res)
}

```

#### 7-2) Testing Function (use only 1 test data) {.tabset}
##### Benign test data
* default = improve svm
```{r}
cancer_diagnosis_predict_p(B)			
```

* Use other ML methods
```{r}
cancer_diagnosis_predict_p(B,learn_imp_c50)
```

##### Malignant test data
* default = improve svm
```{r}
cancer_diagnosis_predict_p(M)
```

* Use other ML methods
```{r}			
cancer_diagnosis_predict_p(M,learn_imp_c50)	
```


#### 7-3) Make Submission Output (use test dataset)
```{r}
library(knitr)

# 테스트 데이터에서 진단 예측 수행
t <- patient[-index,]
origin <- t$diagnosis
t$diagnosis <- NULL
predictions <- cancer_diagnosis_predict_s(t)

# 결과 데이터프레임 생성
sub <- data.frame(id = t$id, predict_diagnosis = ifelse(predictions == 'Malignant', 'M', 'B'), orgin_diagnosis = origin)
sub$correct <- ifelse(sub$predict_diagnosis == sub$orgin_diagnosis, "True", "False")

# 결과 출력 및 CSV 파일 저장
kable(head(sub, 10))
write.csv(sub[, c(1, 2)], file = 'submission.csv', row.names = FALSE)

```


---

### Step 8: Visualize (Probabilty Density Function Graph)
환자를 위해 암을 진단하는 의사들을 위해 이 플롯을 만들었습니다.
환자 입장에서 진단 결과를 **patients diagnosis strong line**을 포함하여 확률밀도 그래프로 시각화하여 환자의 상태를 한 번에 확인할 수 있도록 하였습니다.

환자의 암 인자가 악성 인자 평균보다 높으면 빨간색 선으로 표시했습니다. 
('_worst' variance 제외)


#### 8-1) Create Visualize Function
```{r visual1}
cancer_summary <- function(new,data) {

# [a] ggplot을 위한 데이터셋을 재구성
library(reshape2)
m_train <- melt(data, id="diagnosis")
m_new <- melt(new[,-1])

# [b] 핵심 변수를 강조하기 위한 변수 설정 (geom_vline-빨강)
key_factors <- c("radius_mean", "perimeter_mean", "area_mean", "perimeter_worst",
                 "texture_worst", "radius_worst", "symmetry_se", "compactness_worst",
                 "concavity_worst", "dimension_worst")
key_col <- ifelse(m_new$variable %in% key_factors, "red", "black")

# [c] 악성 값의 평균 및 색상 저장
library(dplyr)
mal_mean <- subset(data, diagnosis == "Malignant", select = -1)
mal_mean <- apply(mal_mean, 2, mean)
library(stringr)
mal_col <- ifelse((round(m_new$value, 3) > mal_mean) & (str_count(m_new$variable, 'worst') < 1), "red", "black")

# [d] 타이틀 및 환자 진단 저장
title <- "유방암 진단 그래프"
subtitle <- cancer_diagnosis_predict_p(new)

# ★[e] 수동으로 지정한 핵심 변수를 강조한 그래프
library(ggplot2)
res_key <- ggplot(m_train, aes(x = value, color = diagnosis, fill = diagnosis)) +
    geom_histogram(aes(y = ..density..), alpha = 0.5, position = "identity", bins = 50) +
    geom_density(alpha = .2) +
    scale_color_manual(values = c("#15c3c9", "#f87b72")) +
    scale_fill_manual(values = c("#61d4d6", "#f5a7a1")) +
    geom_vline(data = m_new, aes(xintercept = value), 
               color = key_col, size = 1.5) +
    geom_label(data = m_new, aes(x = Inf, y = Inf, label = round(value, 3)), nudge_y = 2,  
               vjust = "top", hjust = "right", fill = "white", color = "black") +
    labs(title = paste(title, "(핵심 변수 강조)"), subtitle = subtitle) +
    theme(plot.title = element_text(face = 'bold', colour = 'black', hjust = 0.5, size = 15)) +
    theme(plot.subtitle = element_text(lineheight = 0.8, hjust = 0.5)) +
    labs(caption = "[훈련 데이터 569개의 위스콘신 유방암 진단 환자 데이터]") +
    facet_wrap(~variable, scales = "free", ncol = 5)

# ★[f] 악성 환자의 평균 이상 값을 강조한 그래프
res_mean <- ggplot(m_train, aes(x = value, color = diagnosis, fill = diagnosis)) +
    geom_histogram(aes(y = ..density..), alpha = 0.5, position = "identity", bins = 50) +
    geom_density(alpha = .2) +
    scale_color_manual(values = c("#15c3c9", "#f87b72")) +
    scale_fill_manual(values = c("#61d4d6", "#f5a7a1")) +
    geom_vline(data = m_new, aes(xintercept = value), 
               color = mal_col, size = 1.5) +
    geom_label(data = m_new, aes(x = Inf, y = Inf, label = round(value, 3)), nudge_y = 2,  
               vjust = "top", hjust = "right", fill = "white", color = "black") +
    labs(title = paste(title, "(악성 환자 평균 이상 값 강조)"), subtitle = subtitle) +
    theme(plot.title = element_text(face = 'bold', colour = 'black', hjust = 0.5, size = 15)) +
    theme(plot.subtitle = element_text(lineheight = 0.8, hjust = 0.5, size = 12)) +
    labs(caption = "[훈련 데이터 569개의 위스콘신 유방암 진단 환자 데이터]") +
    facet_wrap(~variable, scales = "free", ncol = 5)

# [g] 출력 그래프
res_mean
# res_key


}
```


#### 8-2) Testing Function {.tabset}
##### Benign
```{r}
cancer_summary(B, breast_cancer_data)
```


##### Malignant
```{r}
cancer_summary(M, breast_cancer_data)
```


---



### Step 9: Visualize (Radar)
This is radar plot to show patient's status of each factor of cancer.

The grey colored area shows **Benigns' Average Area**.


#### 9-1) Create Visualize Function
```{r radar}
cancer_radar <- function(new,data) {

# [a] CoordRadar 함수 정의
coord_radar <- function(theta = "x", start = 0, direction = 1) 
{
        theta <- match.arg(theta, c("x", "y"))
        r <- ifelse(theta == "x", "y", "x")
        ggproto("CoordRadar", CoordPolar, theta = theta, r = r, start = start, 
                direction = sign(direction),
                is_linear = function(coord) TRUE)
}

# [b] 정규화 함수 정의 (rescale 대신 사용 가능)
normalize <- function(x) {
	return((x - min(x)) / (max(x) - min(x)))
}

# [c] 정상(Benign) 데이터에서 평균을 구하여 기준 설정 (회색 영역)
b1 <- subset(data, diagnosis == "Benign", select = -1)
b2 <- as.data.frame(lapply(b1, normalize))           
be <- colMeans(b2)

# [d] 환자 데이터를 정규화하여 정상 데이터와 비교
p_new <- (new[, -1] - apply(b1, 2, min)) / (apply(b1, 2, max) - apply(b1, 2, min))
max_value <- max(p_new)

# [e] 두 데이터를 결합 (정상, 환자)
cc_radar <- rbind(be, p_new)
cc_radar <- cbind(group = c("Normal", "Patient"), cc_radar)

coc <- melt(cc_radar, id = "group")
library(stringr)
coc$variable <- as.character(coc$variable)
coc$variable[str_count(coc$variable, '\\_') > 1] <- sub('_', '.', coc$variable[str_count(coc$variable, '\\_') > 1])
name <- unlist(strsplit(as.character(coc$variable), "_"))

coc$feature <- name[c(seq(1, length(name), 2))]
coc$type <- name[c(seq(2, length(name), 2))]	
coc$variable <- NULL

df <- coc[order(coc$feature),]

# [f] 제목 및 부제목 설정
title <- "Breast Cancer Diagnosis Radar"
subtitle <- cancer_diagnosis_predict_p(new)

# [g] Radar plot
res <- ggplot(df, aes(x = feature, y = value, group = group, fill = group, color = group)) +
	geom_point() + geom_polygon(alpha = 0.3) + coord_radar() + ylim(0, max_value) +
	scale_color_manual(values = c(NA, "#b10000")) +
	scale_fill_manual(values = c("#8e8e8e", NA)) +
	facet_wrap(~type) +
	theme(panel.background = element_rect(fill = "white", colour = NA),
          panel.border = element_rect(fill = NA, colour = "grey50"), 
     	  panel.grid.major = element_line(colour = "grey90", size = 0.2),
    	  panel.grid.minor = element_line(colour = "grey98", size = 0.5),
   	      legend.position = "bottom",
   	      strip.background =  element_rect(fill = "grey80", colour = "grey50"),
   	      axis.text.y = element_text(colour = NA),
   	      axis.title.y = element_text(colour = NA),
   	      axis.ticks = element_line(colour = NA)) +
	      xlab("") + ylab("") +
	labs(title = title, subtitle = subtitle) +
    theme(plot.title = element_text(face = 'bold', colour = 'black', hjust = 0.5, size = 15)) +
    theme(plot.subtitle = element_text(lineheight = 0.8, hjust = 0.5, size = 12)) +
    labs(caption = "[Training 569 wisc cancer diagnostic patient data]")

# [h] 그래프 출력
res

}
```



#### 9-2) Testing Function {.tabset}
##### Benign
```{r}
library(ggplot2)   

cancer_radar(B,breast_cancer_data)
```


##### Malignant
```{r}
cancer_radar(M,breast_cancer_data)	
```


---

### Step 10: Conclusion

저는 최근에 이진 분류를 사용하여 이 **wisconsin breast cancer dataset**의 Python 버전을 업로드했습니다.

기존 ML 방법을 사용하지 않고 이 데이터 세트에 맞게 조정된 인공 신경망 모델을 만듭니다.

- **Python Version**  [here](https://www.kaggle.com/mirichoi0218/ann-making-model-for-binary-classification)

