---
title: "Medical_Cost_code_03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Medical Cost analysis

선형 회귀를 이용한 보험 예측

간략하게 소개하자면, tidymodels는 tidyverse와 마찬가지로 단일 패키지가 아니라 tidyverse 원칙에 따라 설계된 데이터 과학 패키지 모음입니다. tidymodels에 있는 많은 패키지는 tidyverse에도 있습니다. 그러나 tidymodel이 tidyverse와 다른 점은 이러한 패키지 중 상당수가 예측 모델링을 위한 것이며 R에서 사용할 수 있는 다양한 기계 학습 방법 모두에 대한 범용 표준 인터페이스를 제공한다는 것입니다.

우리는 health insurance information(건강 보험 회사)의 고객 약 1,300명으로부터 얻은 건강 보험 정보 데이터 세트를 사용하고 있습니다. 이 데이터 세트는 Brett Lantz가 쓴 Machine Learning with R이라는 책에서 가져온 것입니다.

### Step 0 : usage library

설치 안된 라이브러리의 경우 설치 필요
```{r}
library(tidyverse)
library(parsnip)
library(recipes)
library(rsample)
library(workflows)
library(yardstick)
library(tune)
library(data.table)
```

```{r}
insur_dt <- fread("./data/medical_cost.csv")
```

```{r}
insur_dt %>% colnames()
```

#### Previously written html code reference

* Age: 보험가입자의 나이
* Sex: 보험가입자의 성별
* BMI: 보험가입자의 BMI 지수
* Children: 부양비를 감당할 자식의 수
* Smoker: 흡연 여부
* Region: 보험 수혜자 거주 지역(4가지)
* Charge: 보험에서 청구되는 개인의 의료비용(predicted value)

```{r}
insur_dt$age %>% summary()
```

```{r}
insur_dt$sex %>% table()
```

```{r}
insur_dt$bmi %>% summary()
```

```{r}
insur_dt$smoker %>% table()
```

```{r}
insur_dt$charges %>% summary()
```

위에서 `parsnip` 및 `recipes`와 같은 패키지를 로드했음을 알 수 있습니다. 이러한 패키지는 다른 패키지와 함께 모델링 및 통계 분석에 사용되는 `meta-package` `tidymodels`를 형성합니다. 여기에서 자세한 내용을 알아볼 수 있습니다. 일반적으로 `library(tidymodels)`를 호출하면 되지만 Kaggle R 노트북에서는 당분간 이를 설치하거나 로드할 수 없는 것 같습니다. 괜찮습니다.

보시다시피, 이 데이터 세트에는 상대적으로 자명한 7개의 서로 다른 변수가 있으며, 그 중 일부는 아마도 자비롭고 항상 사랑받는 문제의 민간 건강 보험 회사에서 특정 개인에게 최종적으로 청구되는 금액을 결정하는 데 사용되는 것으로 추정됩니다. 연령, 성별, 지역은 인구통계학적으로 나타납니다. 연령은 18세 이상 64세 이하이며 평균은 약 40세입니다. 성별의 두 가지 요인 수준은 양적으로 거의 동일한 것으로 보입니다.

CDC에 따르면 변수 bmi가 체질량 지수에 해당한다고 가정하면 BMI 30 이상이면 임상적으로 비만으로 간주됩니다. 현재 데이터 세트에서 평균은 비만의 정점을 약간 넘었습니다.

다음으로 흡연자 수와 비흡연자 수를 살펴보겠습니다. 제 인생에서 양식을 한 번이라도 작성해 본 사람으로서, 앞으로 각 건강 보험 고객의 비용을 결정하는 데 흡연자가 중요할 것이라고 확실히 말씀드릴 수 있습니다.

마지막으로 `charge`가 있습니다. health insurance(건강 보험)에 대한 평균 연간 청구액은 $13,000입니다.


```{r}
# 1, 2, 3, 4 etc. children as factor
insur_dt$children <- insur_dt$children %>% as.factor()

insur_dt
```

먼저 어린이 수를 factor levels(요인 수준)으로 저장하는 것부터 시작하고 싶습니다. 실제 생활에서 자녀의 수는 실제로 연속 변수이기 때문에 나중에 분석하는 데 도움이 될 것입니다(보통 매우 제한적이며 대부분의 사람들은 최대 몇 명을 넘지 않습니다).

### Step 1 : Exploratory Data Analysis(EDA)
탐색적 데이터 분석

```{r}
skimr::skim(insur_dt)

table(insur_dt$sex)
```

이 데이터 세트는 매우 깨끗하다는 점을 언급하고 싶습니다. 아마 실제로는 이와 같은 데이터 세트를 접하지 못할 것입니다. NA도 없고, 앞서 언급했듯이 성별에 따른 계급 불균형도 없습니다.

`children` 의  분포를 살펴보겠습니다:

```{r}
table(insur_dt$children)
```

0명의 자녀가 있는 경우: 574명

1명의 자녀가 있는 경우: 324명

2명의 자녀가 있는 경우: 240명

3명의 자녀가 있는 경우: 157명

4명의 자녀가 있는 경우: 25명

5명의 자녀가 있는 경우: 18명

꽤 표준적입니다. 이 세트에 포함된 다수의 사람들에게는 자녀가 없습니다. 그 다음으로 높은 수치는 1, 두 번째로 높은 수치는 2 등입니다.

```{r}
options(repr.plot.width=15, repr.plot.height = 10)

insur_dt %>% 
  select(age, bmi, children, smoker, region, charges) %>%
  GGally::ggpairs(mapping = aes(color = region))

```

`GGally`는 제가 잘 모르는 패키지이지만, 여기에 `ggpairs`라는 함수가 포함되어 있다는 것은 알고 있습니다. 이 함수는 사용자가 입력한 변수로 다양한 플롯을 생성하고 개요를 얻는 데 도움이 됩니다. 그들 사이에 존재하는 관계의. 이러한 플롯의 대부분은 단지 노이즈일 뿐이지만 왼쪽 하단의 두 개는 요금 대 연령 및 `charge(요금) vs bmi` 를 평가하는 것과 같은 몇 가지 흥미로운 플롯이 있습니다. 오른쪽에는 ``charge(요금)` vs `smoker` 도 있습니다. 이러한 관계 중 일부를 자세히 살펴보겠습니다.

```{r}
insur_dt %>% ggplot(aes(color = region)) + facet_wrap(~ region)+
  geom_point(mapping = aes(x = bmi, y = charges))
```

다른 지역과 다른 요금이 부과되는 지역이 있는지 확인하고 싶었지만 이 플롯은 기본적으로 모두 동일해 보입니다. 알다시피, 0,0에서 플롯 중앙까지 투영되는 두 개의 서로 다른 얼룩이 있습니다. 이에 대해서는 나중에 다시 다루겠습니다.

```{r}
insur_dt %>% ggplot(aes(color = region)) + facet_wrap(~ region)+
  geom_point(mapping = aes(x = age, y = charges))
```

여기에서는 `age` 와 `charge(요금)` 사이에 눈에 띄는 관계가 있는지 확인하고 싶었습니다. 4개 지역 전체에서 대부분은 나이가 들수록 완만하게 증가하는 X축 근처의 경사면에 있는 경향이 있습니다. 그러나 해당 기준선에서 두 가지 수준으로 나타나는 패턴이 있습니다. 이들 사람들이 어떤 종류의 `health insurance(건강 보험)`을 사용하고 있는지에 대한 변수가 없기 때문에 현재로서는 이것이 무엇일지 판단을 보류해야 할 것 같습니다.

의심할 여지 없이 `health insurance(건강 보험)` 의 가장 중요한 부분인 `smokers`에 대해 살펴보겠습니다.

```{r}
insur_dt %>%
    select(smoker, bmi, charges) %>%
    ggplot(aes(color = smoker)) +
    geom_point(mapping = aes(x = bmi, y = charges))
```

우와. 정말 큰 차이입니다. 여기에서 `smoker`가 `non-smokers`와 별개로 완전히 새로운 점 덩어리를 거의 생성한다는 것을 알 수 있습니다. 그리고 그 덩어리는 bmi = 30 이후에 급격히 증가합니다. 예를 들어, 비만에 대한 CDC 공식 기준은 무엇이었습니까?

```{r}
insur_dt$age_bins <- cut(insur_dt$age,
                breaks = c(18,20,30,40,50,60,70,80,90),
                include.lowest = TRUE,
                right = TRUE)

insur_dt %>%
    select(bmi, charges, sex, age_bins) %>%
    ggplot(aes(color = age_bins)) +
    geom_point(mapping = aes(x = bmi, y = charges))
```

`age`가 중요한 역할을 한다는 것을 알 수 있지만 여전히 `3-ish clusters of points` 내에서 계층화되어 있으므로 `BMI`가 높은 `smoker` 사이에서도 젊은 사람들은 여전히 일관된 방식으로 노인들보다 적은 돈을 지불합니다. 그러나 나이가 `bmi` or `smoker`와 상호 작용하는 것으로 보이지는 않습니다. 즉, 이는 독립적으로 `charge(요금)`에 영향을 미친다는 의미입니다.

```{r}
insur_dt %>%
    select(children, charges, sex) %>%
    ggplot(aes(x = children, y = charges, group = children)) +
    geom_boxplot(outlier.alpha = 0.5, aes(fill = children)) + 
    theme(legend.position = "none")
```

마지막으로 `children` 는 `charge(요금)`에 큰 영향을 미치지 않습니다.

나는 우리가 `BMI`와 `smoker`가 함께 충전에 시너지 효과를 형성하고 나이도 충전에 영향을 미친다는 것을 입증하기 위해 충분한 탐구 분석을 수행했다고 생각합니다.

<br>

### Step 2 : Build Model

```{r}
set.seed(123)

insur_split <- initial_split(insur_dt, strata = smoker)

insur_train <- training(insur_split)
insur_test <- testing(insur_split)

# `recipes`를 사용하여 데이터 처리 및 기능 엔지니어링을 수행할 예정입니다.
# 아래에서는 다른 모든 항목(".")을 사용하여 `charges`을 예측하겠습니다.
insur_rec <- recipe(charges ~ bmi + age + smoker, data = insur_train) %>%
    step_dummy(all_nominal()) %>%
    step_normalize(all_numeric(), -all_outcomes()) %>%
    step_interact(terms = ~ bmi:smoker_yes)

test_proc <- insur_rec %>% prep() %>% bake(new_data = insur_test)
```

먼저 데이터를 훈련 세트와 테스트 세트로 분할했습니다. 불균형이 있고 훈련 및 테스트 데이터 세트 모두에서 동일하게 표현되기를 원하기 때문에 흡연자 상태별로 샘플링을 계층화합니다. 이는 먼저 해당 클래스 내에서 무작위 샘플링을 수행하여 수행됩니다.

* `recipe`에 대한 설명

1. `BMI`, `age`, `smoker`가 `charge`에 미치는 영향을 모델링하겠습니다. `recipe`는 상호작용을 단계로 처리하므로 이 단계에서는 상호작용을 지정하지 않습니다.
2. 모든 명목 예측 변수에 대해 `step_dummy`(더미 변수)를 생성하므로 `smoker`는 `smoker_yes`가 되고 `smoker_no`는 생략을 통해 `implied` 됩니다(따라서 행에 `smoker_yes == 0`이 있는 경우). 일부 모델은 모든 더미를 가질 수 없기 때문입니다. 열로 존재하는 변수. 모든 더미 변수를 포함하려면 `one_hot = TRUE`를 사용할 수 있습니다.
3. 그런 다음 결과 변수(`step_normalize(all_numeric(), -all_outcomes())`)를 제외한 모든 숫자 예측 변수를 정규화합니다. 일반적으로 다른 데이터 세트가 모델과 일치하지 않도록 모델을 훈련하고 개발할 때 결과에 대한 변환을 피하고 싶기 때문입니다. 당신이 사용하고 있는 것이 와서 당신의 모델을 망가뜨립니다. `recipe`를 만들기 전에 결과에 대한 변환을 수행하는 것이 가장 좋습니다.
4. 상호작용 기간을 설정하고 있습니다. `bmi`와 `smoker_yes`(`smoker`에 대한 더미 변수)는 모두 결과에 영향을 미칠 때 서로 상호 작용합니다. 이전에 우리는 노인 환자에게 더 많은 비용이 청구되고, BMI가 더 높은 노인 환자에게는 그보다 더 많은 비용이 청구된다는 사실을 확인했습니다. 음, 흡연을 하는 체질량 지수가 높은 노인 환자는 우리 데이터 세트에 있는 누구보다 가장 많은 비용을 청구받습니다. 우리는 플롯을 볼 때 이를 시각적으로 관찰했기 때문에 개발할 모델에서도 이를 테스트할 예정입니다.

실제로 모델을 지정해 보겠습니다. 우리는 단지 재미를 위해 `k-Nearest Neighbors` 모델을 사용하여 작업할 것입니다. KNN 모델은 간단하게 다음과 같이 정의됩니다(인터넷 검색 후 온라인에서 찾은 일부 R 마크다운 책에 따르면 `knn simplified(knn 단순화)`).

`KNN regression(KNN 회귀)`는 동일한 지역의 관측치를 평균하여 독립 변수와 연속 결과 간의 연관성을 직관적인 방식으로 근사화하는 비모수적 방법입니다. 이웃의 크기는 분석가가 설정해야 하거나 평균 제곱 오차를 최소화하는 크기를 선택하기 위해 교차 검증(나중에 설명)을 사용하여 선택할 수 있습니다.

단순하게 유지하기 위해 최적의 `k`를 찾기 위해 교차 검증을 사용하지 않을 것입니다. 대신, 우리는 `k = 10`이라고 말할 것입니다. 내가 찾은 또 다른 웹사이트에서는 `k = sqrt(n)`을 유지하는 것이 좋은 경험 법칙이라고 말했습니다. Kaggle의 컴퓨팅 서버가 이를 처리할 수 있다고 생각하지만 `nrow(insur_dt) ≒ 37`이기 때문에 그렇게 하지 않을 것입니다. 그래서 안 되는 이유는 모르겠습니다.

```{r}
knn_spec <- nearest_neighbor(neighbors = 10) %>%
    set_engine("kknn") %>%
    set_mode("regression")

knn_fit <- knn_spec %>%
    fit(charges ~ age + bmi + smoker_yes + bmi_x_smoker_yes,
        data = juice(insur_rec %>% prep()))

insur_wf <- workflow() %>% 
    add_recipe(insur_rec) %>% 
    add_model(knn_spec)
```

`parsnip`에서 모델 자체를 호출하여 `knn_spec` 모델을 지정한 다음 `set_engine`을 설정하고 모드를 회귀로 설정했습니다. `Nearest_neighbor`의 neighbor 매개변수를 참고하세요. 이는 knn의 k에 해당합니다.

그런 다음 모델 사양을 사용하여 모델을 데이터에 맞춥니다. `bmi` 및 `smoker_yes` 상호 작용에 대한 열을 이미 계산했기 때문에 상호 작용을 공식적으로 다시 표현할 필요가 없습니다.

이 모델을 평가하여 좋은지 나쁜지 살펴보겠습니다.

```{r}
insur_cv <- vfold_cv(insur_train, v = 10)  # 예시로 v = 10 사용

insur_rsmpl <- fit_resamples(insur_wf,
                             insur_cv,
                             control = control_resamples(save_pred = TRUE))

insur_rsmpl %>% collect_metrics()

summary(insur_dt$charges)

```

우리는 `vfold_cv`(대부분의 사람들에게 친숙한 교차 검증으로, 훈련 데이터가 V 접기로 분할된 다음 마지막 접기에 대한 예측을 위해 V-1 접기에 대해 훈련되고 반복됨)를 설정했습니다. 모든 접기가 훈련되고 예측 접기로 사용되도록) '0.9'의 'prop'로 설정합니다. 이는 훈련 데이터 내에서 9개의 훈련 접기와 1개의 테스트 접기를 지정하는 것과 같습니다.(prop 0.9로 했을때 에러 발생해서 예시로 v = 10 사용)

그런 다음 마지막으로 `fit_resamples`를 사용하여 교차 검증을 실행합니다. 보시다시피 우리는 워크플로 개체를 입력으로 사용했습니다.

마지막으로 `collect_metrics`를 호출하여 모델 효율성을 검사합니다. 결국 `rmse`는 4,915이고 `rsq`는 `0.82`입니다. RMSE는 평균적으로 우리의 예측이 관측된 값과 절대값 4,915(이 경우에는 `charge` 단위)만큼 다양하다고 제안합니다. `R^2`는 회귀 분석의 적합도가 `~82%`임을 시사합니다. 하지만 `R^2`가 높다고 해서 모델의 적합도가 항상 좋은 것은 아니며, `R^2`가 낮다고 해서 모델이 항상 적합하다는 의미는 아닙니다. 나 이외의 이유로 적합하지 않습니다.

```{r}
# insur_rsmpl 데이터프레임을 .predictions 열을 기준으로 펼침
insur_rsmpl %>% 
    unnest(.predictions) %>% 
    # 산점도 그리기
    ggplot(aes(charges, .pred, color = id)) + 
    # 회귀선 추가 (dashed line, 회색, 굵기 1.5)
    geom_abline(lty = 2, color = "gray80", linewidth = 1.5) + 
    # 산점도 추가 (투명도 0.5)
    geom_point(alpha = 0.5) + 
    # 범례 제거
    theme(legend.position = "none")

```

위의 출력값을 보면 회귀가 선에 맞는 모습을 보여줍니다. 모델이 포착하지 못하는 대규모 값 클러스터가 있으며 이러한 점에 대해 더 많이 배울 수 있지만 대신 이 프로젝트에서 훨씬 일찍 정의한 테스트 데이터에 모델을 적용하는 단계로 넘어갈 것입니다.

```{r}
insur_test_res <- predict(knn_fit, new_data = test_proc %>% select(-charges))

insur_test_res <- bind_cols(insur_test_res, insur_test %>% select(charges))

insur_test_res
```

이제 모델을 `test_proc`에 적용했습니다. 이는 훈련 데이터를 변환한 것과 동일한 방식으로 모델을 변환하기 위해 `recipes`` 전처리 단계를 사용한 후의 테스트 세트입니다. 결과 예측을 훈련 데이터에서 발견된 실제 요금과 결합하여 예측과 예측하려고 시도한 해당 실제 값이 포함된 2열 테이블을 만듭니다.

```{r}
# ggplot을 사용하여 예측값과 실제값의 산점도를 그립니다.
ggplot(insur_test_res, aes(x = charges, y = .pred)) + 
  # 대각선 선을 그립니다:
  geom_abline(lty = 2) + 
  # 산점도를 그립니다:
  geom_point(alpha = 0.5) + 
  # 축의 레이블을 설정합니다: 
  labs(y = "Predicted Charges", x = "Charges") +
  # x축과 y축을 동일하게 스케일링하고 크기를 일치시킵니다:
  coord_obs_pred()
```

```{r}
rmse(insur_test_res, truth = charges, estimate = .pred)

insur_rsmpl %>% collect_metrics()
```

테스트 데이터로 생성된 RMSE는 교차 검증으로 생성된 RMSE와 크게 다르지 않습니다. 이는 우리 모델이 거의 동일한 수준의 오류로 예측을 안정적으로 재현할 수 있음을 의미합니다.

솔직히 말해서 이제 둘 사이의 결과를 비교하기 위해 동일한 방식으로 선형 회귀 모델을 구성하고 싶습니다. 다행스럽게도 `tidymodels`를 사용하면 이를 쉽게 수행할 수 있습니다.

<br>

### Linear Regression

우리는 이미 `recipe`를 가지고 있습니다. 이제 우리에게 필요한 것은 선형 모델을 지정하고 테스트 데이터에 대해 테스트하기 위해 적합성을 교차 검증하는 것입니다.

```{r}
lm_spec <- linear_reg() %>% set_engine("lm")

lm_fit <- lm_spec %>%
    fit(charges ~ age + bmi + smoker_yes + bmi_x_smoker_yes,
        data = juice(insur_rec %>% prep()))

insur_lm_wf <- workflow() %>% 
    add_recipe(insur_rec) %>% 
    add_model(lm_spec)
```

KNN에서 했던 것과 동일한 단계 중 일부를 반복하지만 선형 모델에서는 그렇습니다. (거의) 동일한 명령을 사용하여 교차 검증할 수도 있습니다.

```{r}
insur_lm_rsmpl <- fit_resamples(insur_lm_wf,
                           insur_cv,
                           control = control_resamples(save_pred = TRUE))

insur_lm_rsmpl %>% collect_metrics()

insur_rsmpl %>% collect_metrics()
```

good, ol' fashioned 선형 모델은 RMSE 측면에서뿐만 아니라 10개의 교차 검증 접기에서 R^2 측면에서도 `k-Nearest Neighbors`를 능가한 것으로 보입니다.

```{r}
insur_test_lm_res <- predict(lm_fit, new_data = test_proc %>% select(-charges))

insur_test_lm_res <- bind_cols(insur_test_lm_res, insur_test %>% select(charges))

insur_test_lm_res
```

이제 예측이 완료되었으므로 선형 모델이 얼마나 잘 수행되었는지 살펴보겠습니다.

```{r}
ggplot(insur_test_lm_res, aes(x = charges, y = .pred)) + 
  # Create a diagonal line:
  geom_abline(lty = 2) + 
  geom_point(alpha = 0.5) + 
  labs(y = "Predicted Charges", x = "Charges") +
  # Scale and size the x- and y-axis uniformly:
  coord_obs_pred()
```

왼쪽 하단에 있는 부분이 `charges` 의 집중이 가장 큰 것으로 보이며, 이는  `lm fit`의 대부분을 설명합니다. 이 두 가지 `plots`을 보면 우리가 사용할 수 있었던 더 나은 모델이 있었는지 궁금합니다. 그러나 우리의 목적과 정확도 수준을 고려할 때 우리의 모델은 충분했습니다.

```{r, warning=FALSE}
combind_dt <- mutate(insur_test_lm_res,
      lm_pred = .pred,  
      charges = charges
      ) %>% select(-.pred) %>% 
    add_column(knn_pred = insur_test_res$.pred) 

ggplot(combind_dt, aes(x = charges)) + 
    geom_line(aes(y = knn_pred, color = "kNN Fit"), size = 1) +
    geom_line(aes(y = lm_pred, color = "lm Fit"), size = 1) +
    geom_point(aes(y = knn_pred, alpha = 0.5), color = "#F99E9E") +
    geom_point(aes(y = lm_pred, alpha = 0.5), color = "#809BF4") +
    geom_abline(size = 0.5, linetype = "dashed") + 
    xlab('Charges') +
    ylab('Predicted Charges') +
    guides(alpha = FALSE)
```

위는 두 가지 방법을 각각의 예측과 `correct` 값을 나타내는 점선으로 비교한 것입니다. 이 경우 두 모델은 서로 `plots`할 때 차이점을 쉽게 관찰할 수 있을 만큼 충분히 다르지 않았지만 앞으로는 두 모델이 실질적으로 다른 경우가 있을 것이며 이런 종류의 플롯은 한 모델을 다른 모델보다 사용하는 사례를 강화합니다.

<br>

### Conclusion

여기에서는 훈련 데이터로 `KNN model`을 구축하고 이를 사용하여 테스트 데이터의 값을 예측할 수 있었습니다. 이를 위해 우리는

* EDA 수행
* `recipes`를 사용하여 데이터를 전처리했습니다.
* 모델을 KNN으로 지정
* 훈련 데이터에 맞춤
* 정확한 오류 통계를 생성하기 위해 교차 검증을 실행
* 테스트 세트의 예측 값
* 관찰된 테스트 세트 값을 예측과 비교
* 다른 모델인 `lm` 을 지정함
* 교차 검증을 수행
* `lm model`이 더 나은 모델임을 발견

<br>

기계 학습 방법을 적용하는 방법으로 R에서 `tidymodel`을 계속 사용하게 되어 매우 기쁩니다. 관심이 있으시면 Max Kuhn과 Julia Silge가 쓴 Tidy Modeling with R을 확인해 보시기 바랍니다.

<br>














