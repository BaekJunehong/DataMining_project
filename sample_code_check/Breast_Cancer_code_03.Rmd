---
title: "Breast_Cancer_code_03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Breast_cancer analysis
* Breast_cancer : 유방암

This dataset can be found in this link: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data

특징은 유방 덩어리의 미세 바늘 흡인(FNA)의 디지털 이미지로부터 계산됩니다. 이는 이미지에 존재하는 세포핵의 특성을 설명합니다. n 3차원 공간은 [K. P. Bennett 및 O. L. Mangasarian: "두 개의 선형 분리 불가능한 세트의 강력한 선형 계획법 판별", Optimization Methods and Software 1, 1992, 23-34]


이 데이터베이스는 UW CS FTP 서버(ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/)를 통해서도 사용할 수 있습니다.

UCI 기계 학습 저장소에서도 찾을 수 있음 https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

## 0. usage library
설치 안된 라이브러리의 경우 설치 필요
```{r}
library(psych, warn.conflicts=F)
library(data.table, warn.conflicts=F)
library(ggplot2,warn.conflicts=F)
library(plotly,warn.conflicts=F)
library(expss,warn.conflicts=F)
library(tidyverse,warn.conflicts=F)
library(pander,warn.conflicts=F)
library(forcats,warn.conflicts=F)
library(stringr,warn.conflicts=F)
library(caTools,warn.conflicts=F)
library(VIM,warn.conflicts=F)
library(caret,warn.conflicts=F)
require(reshape2,warn.conflicts=F)
library(GGally,warn.conflicts=F)
library(corrplot,warn.conflicts=F)
library(factoextra,warn.conflicts=F)
library(gridExtra,warn.conflicts=F)
library(C50,warn.conflicts=F)
library(highcharter,warn.conflicts=F)
library(rpart,warn.conflicts=F)
library(e1071,warn.conflicts=F)
library(ranger,warn.conflicts=F)
library(epiR,warn.conflicts=F)
library(randomForest,warn.conflicts=F)
library(party,warn.conflicts=F)
library(class,warn.conflicts=F)
library(kknn,warn.conflicts=F) 
library(gbm,warn.conflicts=F)
library(ada,warn.conflicts=F)
```

## Step 1: Dataset

데이터 세트 및 세부 정보는 여기에서 확인할 수 있습니다: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data#data.csv

Codeadd 마크다운 추가
데이터세트에는 33개의 열이 있는데 한 개는 완전히 비어 있어 제거

```{r}
breast_cancer_data <- read.csv("./data/breast_cancer.csv", header=T)

str(breast_cancer_data)

# 마지막열(33) 제외
breast_cancer_data <- breast_cancer_data[,-33]
```

<br>

### 변수 설명 (32개)

##### id 및 diagnosis (2개)(0:1)
* id (ID 번호): 각 환자의 고유 식별 번호
* diagnosis (진단): 유방 조직의 진단 결과 (M = malignant(악성), B = benign(양성))

참고 내용

진단 (Diagnosis)

양성 (Benign): 양성 종양은 일반적으로 비교적 덜 위험하며, 주변 조직에 침범 X

악성 (Malignant): 악성 종양은 주변 조직으로의 침입이나 전이 가능성이 있으며, 더 높은 위험을 내포

##### mean (10개)(2:11)
* radius_mean (반경 평균): 중심에서 둘레까지의 거리의 평균
* texture_mean (질감 평균): gray-scale 값의 표준 편차
* perimeter_mean (둘레 평균): 핵 종양의 평균 크기
* area_mean (면적 평균): 핵 종양의 면적의 평균
* smoothness_mean (매끄러움 평균): 반지름 길이의 지역 변동의 평균
* compactness_mean (조그만함 평균): 둘레^2 / 면적 - 1.0의 평균
* concavity_mean (오목함 평균): 등고선의 오목한 부분의 심각도의 평균
* concave points_mean (오목한 지점 평균): 등고선의 오목한 부분의 수의 평균
* symmetry_mean (대칭성 평균): 대칭성의 평균
* fractal_dimension_mean (프랙탈 차원 평균): "coastline approximation(해안선 근사치)" - 1의 평균

##### se (10개)(12:21)
* radius_se (반경 표준 오차): 중심에서 둘레까지의 거리의 평균의 표준 오차
* texture_se (질감 표준 오차): gray-scale 값의 표준 편차의 표준 오차
* perimeter_se (둘레 표준 오차): 핵 종양의 평균 크기의 표준 오차
* area_se (면적 표준 오차): 핵 종양의 면적의 표준 오차
* smoothness_se (매끄러움 표준 오차): 반지름 길이의 지역 변동의 표준 오차
* compactness_se (조그만함 표준 오차): 둘레^2 / 면적 - 1.0의 표준 오차
* concavity_se (오목함 표준 오차): 등고선의 오목한 부분의 심각도의 표준 오차
* concave points_se (오목한 지점 표준 오차): 등고선의 오목한 부분의 수의 표준 오차
* symmetry_se (대칭성 표준 오차): 대칭성의 표준 오차
* fractal_dimension_se (프랙탈 차원 표준 오차): "coastline approximation" - 1의 표준 오차

##### worst (10개)(22:31)
* radius_worst (반경 최악): 중심에서 둘레까지의 거리의 평균의 최대값
* texture_worst (질감 최악): gray-scale 값의 표준 편차의 최대값
* perimeter_worst (둘레 최악): 핵 종양의 평균 크기의 최대값
* area_worst (면적 최악): 핵 종양의 면적의 최대값
* smoothness_worst (매끄러움 최악): 반지름 길이의 지역 변동의 최대값
* compactness_worst (조그만함 최악): 둘레^2 / 면적 - 1.0의 최대값
* concavity_worst (오목함 최악): 등고선의 오목한 부분의 심각도의 최대값
* concave points_worst (오목한 지점 최악): 등고선의 오목한 부분의 수의 최대값
* symmetry_worst (대칭성 최악): 대칭성의 최대값
* fractal_dimension_worst (프랙탈 차원 최악): "coastline approximation" - 1의 최대값

<br>

## Step 2: The endpoint

종양이 Malignant(악성) or Benign(양성) 를 정확하게 분류할 수 있는 기계 학습 알고리즘을 설계

<br>

## Step 3: Missing data

* 누락된 데이터가 있는지 확인 
아래 출력 결과를 통해 누락된 데이터가 없음을 확인 가능
* 데이터 프레임에서 각 열(변수)에 대한 결측값의 비율을 계산하고 시각화

```{r}
# summarize_all() -> 각 열에 대해 주어진 함수를 적용하여 요약 통계를 계산
missing_values <- breast_cancer_data %>% summarize_all(list(missing_pct = ~sum(is.na(.))/n()))

# gather() -> "long" 형식으로 변환하여 시각화에 적합한 형태로 만듬
missing_values <- gather(missing_values, key="feature", value="missing_pct")

# ggplot 함수를 사용하여 막대 그래프를 생성
missing_values %>% 
  ggplot(aes(x=reorder(feature, -missing_pct), y=missing_pct)) +
  geom_bar(stat="identity", fill="red") +
  coord_flip() +
  theme_bw()

```

* 누락된 데이터가 없어 패턴이 없음

```{r, warning=FALSE}
# aggr 함수는 'VIM' 패키지에 속한 함수로서, 데이터셋의 결측값을 다양한 그래픽으로 요약하여 제공
## data: 시각화할 데이터프레임
## prop: 각 변수별 결측값 비율을 보여줄지 여부 (기본값: FALSE)
## combined: 결측값이 있는 행 또는 열을 표시하는 방법 (기본값: TRUE)
## numbers: 숫자를 사용하여 그래프를 그릴지 여부 (기본값: TRUE)
## sortVars: 변수들을 결측값의 비율에 따라 정렬할지 여부 (기본값: TRUE)
## sortCombs: 그래픽 표현을 정렬할지 여부 (기본값: TRUE)

aggr(data, prop = FALSE, combined = TRUE, numbers = TRUE, sortVars = TRUE, sortCombs = TRUE)
```

<br>


## Step 4: Target variable

```{r}
# about diagnosis variable

## 빈도표
table(breast_cancer_data$diagnosis)

## 상대 빈도표
prop.table(table(breast_cancer_data$diagnosis))*100
```

* Target variable 는 문자형 변수이므로 팩터로 변환하는 것을 권장

```{r}
# 팩터로 변환
breast_cancer_data$diagnosis <- factor(breast_cancer_data$diagnosis, labels=c('B','M'))

# 상대 빈도표 재출력
prop.table(table(breast_cancer_data$diagnosis))*100
```

<br>


## Step 5: Descriptive analysis

* psych::는 R에서 패키지 함수를 지정할 때 사용되는 표기법 중 하나
* R에서 여러 패키지가 동일한 이름의 함수를 가질 수 있기 때문에 특정 패키지의 함수를 사용하려면 함수 이름 앞에 패키지이름::을 붙여서 명시적으로 지정

```{r}
# psych 패키지의 describeBy 함수 사용
# 데이터프레임의 3번째부터 32번째 열까지의 변수를 diagnosis 열을 기준으로 그룹화하여 각 그룹에 대한 요약 통계량을 생성
psych::describeBy(breast_cancer_data[3:32], group = breast_cancer_data$diagnosis)
```

* 이 플롯은 일반적으로 악성 진단이 모든 변수에서 더 높은 점수를 갖는다는 것을 보여줍니다.

```{r}
#Mean
df.m <- melt(breast_cancer_data[,-c(1,13:32)], id.var = "diagnosis")
p <- ggplot(data = df.m, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=diagnosis)) + facet_wrap( ~ variable, scales="free")+ xlab("Variables") + ylab("")+ guides(fill=guide_legend(title="Group"))
p

#Se
df.m <- melt(breast_cancer_data[,-c(1,3:12,23:32)], id.var = "diagnosis")
p <- ggplot(data = df.m, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=diagnosis)) + facet_wrap( ~ variable, scales="free")+ xlab("Variables") + ylab("")+ guides(fill=guide_legend(title="Group"))
p

#Worst
df.m <- melt(breast_cancer_data[,c(2,23:32)], id.var = "diagnosis")
p <- ggplot(data = df.m, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=diagnosis)) + facet_wrap( ~ variable, scales="free")+ xlab("Variables") + ylab("")+ guides(fill=guide_legend(title="Group"))
p
```

<br>


## Step 6: Correlations

* 아래 제시된 플롯은 변수 간의 패턴을 이해하기 위해 변수별로 패키지화 되어있음
* 이를 통해 일부 변수 사이에 매우 높은 상관관계가 있음을 알 수 있음

```{r}
pairs.panels(breast_cancer_data[,c(3:12)], method="pearson",
             hist.col = "#1fbbfa", density=TRUE, ellipses=TRUE, show.points = TRUE,
             pch=1, lm=TRUE, cex.cor=1, smoother=F, stars = T, main="Cancer Mean")

pairs.panels(breast_cancer_data[,c(13:22)], method="pearson",
             hist.col = "#1fbbfa", density=TRUE, ellipses=TRUE, show.points = TRUE,
             pch=1, lm=TRUE, cex.cor=1, smoother=F, stars = T, main="Cancer SE")

pairs.panels(breast_cancer_data[,c(23:32)], method="pearson",
             hist.col = "#1fbbfa", density=TRUE, ellipses=TRUE, show.points = TRUE,
             pch=1, lm=TRUE, cex.cor=1, smoother=F, stars = T, main="Cancer Worst")
```

```{r}
w.corr<-cor(breast_cancer_data[,c(3:12)],method="pearson")
corrplot(w.corr, order='hclust', method='ellipse',addCoef.col = 'black',type='lower', number.cex = 1,tl.cex = 1, diag=F,tl.col = 'black',tl.srt=15)

w.corr<-cor(breast_cancer_data[,c(13:22)],method="pearson")
corrplot(w.corr, order='hclust', method='ellipse',addCoef.col = 'black',type='lower', number.cex = 1,tl.cex = 1, diag=F,tl.col = 'black',tl.srt=15)

w.corr<-cor(breast_cancer_data[,c(23:32)],method="pearson")
corrplot(w.corr, order='hclust', method='ellipse',addCoef.col = 'black',type='lower', number.cex = 1,tl.cex = 1, diag=F,tl.col = 'black',tl.srt=15)
```

```{r}
w.corr<-cor(breast_cancer_data[,c(3:32)],method="pearson")
corrplot(w.corr, order='hclust', method='ellipse',addCoef.col = 'black',type='lower', number.cex = 0.25,tl.cex = 0.25, diag=F,tl.col = 'black',tl.srt=15)
```

```{r}
# heatmap 그리기
col <- colorRampPalette(c('blue', 'white', 'orange'))(20)
heatmap(x=w.corr, col=col, symm=T)
```

<br>

## Step 7: Training and testing datasets

```{r}
dataset <- breast_cancer_data

head(dataset)
```

* 데이터 세트는 training (70%)과 testing (30%)의 두 가지 데이터 세트로 나뉩니다.

```{r}
set.seed(123)
smp_size <- floor(0.70 * nrow(dataset))
train_ind <- sample(seq_len(nrow(dataset)), size = smp_size)

#  training (70%)
train <- dataset[train_ind, ]

# testing (30%)
test <- dataset[-train_ind, ]
```

* Let's check the target variable.

```{r}
# train
prop.table(table(train$diagnosis))*100

# test
prop.table(table(test$diagnosis))*100
```

<br>


## Step 8: machine learning

<br>


### ML 1: Quinlan's C5.0

Training the model.

```{r}
names(train)
```

```{r}
learn_c50 <- C5.0(train[,-c(1,2)],train$diagnosis)
learn_c50
```

Testing the model.

```{r}
pre_c50 <- predict(learn_c50, test[,-c(1,2)])
cm_c50 <- confusionMatrix(pre_c50, test$diagnosis)
cm_c50
```

<br>


### ML 2: Quinlan's C5.0 tunned

```{r}
# 초기화
acc_test <- numeric()
accuracy1 <- NULL; accuracy2 <- NULL

# 1부터 50까지의 시도 횟수에 대해 반복
for(i in 1:50){
    # C5.0 모델 학습
    learn_imp_c50 <- C5.0(train[,-c(1,2)], train$diagnosis, trials = i)      
    
    # 테스트 데이터에 대한 예측
    p_c50 <- predict(learn_imp_c50, test[,-c(1,2)]) 
    
    # 혼동 행렬 계산 및 정확도 저장
    accuracy1 <- confusionMatrix(p_c50, test$diagnosis)
    accuracy2[i] <- accuracy1$overall[1]
}

# 결과 데이터프레임 생성
acc <- data.frame(t = seq(1, 50), cnt = accuracy2)

# 최적의 시도 횟수 추출
opt_t <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of trials is", opt_t$t, "(accuracy:", opt_t$cnt, ") in C5.0")

# Highcharter를 사용한 그래프 생성
hchart(acc, 'line', hcaes(t, cnt)) %>%
  hc_title(text = "Accuracy With Varying Trials (C5.0)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Trials")) %>%
  hc_yAxis(title = list(text = "Accuracy"))

```

```{r}
# 훈련 중 가장 높은 정확도를 보이는 epoch일때의 모델을 사용
# opt_t$t는 최적의 횟수로 설정된 변수
learn_imp_c50 <- C5.0(train[,-c(1,2)],train$diagnosis,trials=opt_t$t)
pre_imp_c50 <- predict(learn_imp_c50, test[,-c(1,2)])
cm_imp_c50 <- confusionMatrix(pre_imp_c50, test$diagnosis)
cm_imp_c50
```

<br>

### ML 3: Rpart (recursive partitioning and regression trees)

```{r}
learn_rp <- rpart(diagnosis~.,data=train[,-1],control=rpart.control(minsplit=2))
```

Testing the model.

```{r}
pre_rp <- predict(learn_rp, test[,-c(1,2)], type="class")
cm_rp  <- confusionMatrix(pre_rp, test$diagnosis)
cm_rp
```

<br>


### ML 4: Prunned Rpart (recursive partitioning and regression trees)

Training the model.

```{r}
learn_pru <- prune(learn_rp, cp=learn_rp$cptable[which.min(learn_rp$cptable[,"xerror"]),"CP"])
```

Testing the model.

```{r}
pre_pru <- predict(learn_pru, test[,-c(1,2)], type="class")
cm_pru <-confusionMatrix(pre_pru, test$diagnosis)
cm_pru
```

<br>


### ML 5: Naive Bayes

Training the model.

```{r}
learn_nb <- naiveBayes(train[,-c(1,2)], train$diagnosis)
```

Testing the model.

```{r}
pre_nb <- predict(learn_nb, test[,-c(1,2)])
cm_nb <- confusionMatrix(pre_nb, test$diagnosis)
cm_nb
```

<br>


### ML 6: Logistic regression

Training the model.

```{r, warning=FALSE}
# trainControl 함수를 사용하여 교차 검증을 설정
fitControl <- trainControl(
  method = "cv",            # 10-fold 교차 검증 선택
  number = 10,               # 10-fold 설정
  savePredictions = TRUE     # 예측 결과 저장 설정
)

# train 함수를 사용하여 로지스틱 회귀 모델 학습
lreg <- train(
  diagnosis ~ .,             # 예측 변수는 diagnosis를 제외한 모든 변수
  data = train[,-1],          # 학습 데이터셋
  method = "glm",             # 로지스틱 회귀 모델 선택
  family = binomial(),        # 이항 분포 선택
  trControl = fitControl      # 교차 검증 설정 적용
)

# 학습된 모델의 변수 중요도 출력
varImp(lreg)

```

Testing the model.

```{r}
lreg_pred<-predict(lreg,test[,-c(1,2)])
cm_logistic<-confusionMatrix(lreg_pred,test$diagnosis)
cm_logistic
```

<br>


### ML 7: Random Forest

Training the model.

```{r}
learn_ranger  <- train(diagnosis ~ ., data = train[,-1], method = "ranger")
learn_ranger
```

Testing the model.

```{r}
pre_ranger <- predict(learn_ranger, test[,-c(1,2)])
cm_ranger <- confusionMatrix(pre_ranger, test$diagnosis)
cm_ranger
```

<br>


### ML 8: Classification tree

Training the model.

```{r}
learn_ct <- ctree(diagnosis~., data=train[,-1], controls=ctree_control(maxdepth=2))
```

Testing the model.

```{r}
pre_ct   <- predict(learn_ct, test[,-c(1,2)])
cm_ct    <- confusionMatrix(pre_ct, test$diagnosis)
cm_ct
```

<br>

### ML 9: K-nn

Training the model.

* repeatedcv : repeated cross-validation / repeated 교차 검증
* 즉 교차검증을 여러 번 반복하는 것을 의미

* tuneLength = 20 :  모델 파라미터의 후보 값들 중에서 20개를 테스트

```{r}
# trainControl 함수를 사용하여 교차 검증을 설정
control <- trainControl(method='repeatedcv', 
                        number=10,           
                        repeats=3)           

# train 함수를 사용하여 k-nn 모델 학습
knnFit <- train(diagnosis ~ .,        
                data = train[,-1],      # 학습 데이터셋
                method = "knn",         # k-nn 모델 선택
                trControl = control,    # 교차 검증 설정 적용
                tuneLength = 20)        # 모델 파라미터 튜닝 범위의 길이

# 학습된 모델의 성능 시각화
plot(knnFit)

```

Testing the model.

```{r}
knnPredict <- predict(knnFit,newdata = test )
cm_knn<-confusionMatrix(knnPredict, test$diagnosis )
cm_knn
```

<br>

### ML 10: K-means

Training the model.

```{r}
predict.kmeans <- function(newdata, object){
    # 클러스터 중심 좌표 가져오기
    centers <- object$centers
    
    # 중심 좌표의 개수
    n_centers <- nrow(centers)
    
    # 새로운 데이터와 클러스터 중심 간의 거리 계산
    dist_mat <- as.matrix(dist(rbind(centers, newdata)))
    
    # 거리 행렬에서 새로운 데이터와의 거리만 추출
    dist_mat <- dist_mat[-seq(n_centers), seq(n_centers)]
    
    # 거리가 가장 작은 클러스터 선택
    max.col(-dist_mat)
}

```

```{r}
learn_kmeans <- kmeans(train[,-c(1,2)], centers=2)
```

Testing the model.

```{r}
pre_kmeans <- predict.kmeans(test[,-c(1,2)],learn_kmeans)
pre_kmeans <- factor(ifelse(pre_kmeans == 1,"B","M"))
cm_kmeans <- confusionMatrix(pre_kmeans, test$diagnosis)
cm_kmeans
```

<br>

### ML 11: Gradient boosting machines(GBM)

Training the model.

```{r}
# GBM 모델 생성
test_gbm <- gbm(
  diagnosis ~ ., 
  data = train[,-1], 
  distribution = "gaussian",
  n.trees = 10000,
  shrinkage = 0.01, 
  interaction.depth = 4, 
  bag.fraction = 0.5, 
  train.fraction = 0.5,
  n.minobsinnode = 10,
  cv.folds = 3,
  keep.data = TRUE,
  verbose = FALSE,
  n.cores = 1
)

# 최적의 트리 개수 찾기
best.iter <- gbm.perf(test_gbm, method="cv",plot.it=FALSE)

# GBM 모델 훈련
fitControl = trainControl(
  method = "cv", 
  number = 5, 
  returnResamp = "all"
)
learn_gbm = train(
  diagnosis ~ ., 
  data = train[,-1], 
  method = "gbm", 
  distribution = "bernoulli", 
  trControl = fitControl, 
  verbose = FALSE, 
  tuneGrid = data.frame(
    .n.trees = best.iter, 
    .shrinkage = 0.01, 
    .interaction.depth = 1, 
    .n.minobsinnode = 1
  )
)

```

* "CV"는 Cross Validation(교차 검증)
* "CV: 1", "CV: 2", "CV: 3"은 세 번의 교차 검증이 진행됨을 나타냄

Testing the model.

```{r}
pre_gbm <- predict(learn_gbm, test[,-c(1,2)])
cm_gbm <- confusionMatrix(pre_gbm, test$diagnosis)
cm_gbm
```

<br>

### ML 12: Adaboost

Training the model.

```{r}
control <- rpart.control(cp = -1, maxdepth = 14,maxcompete = 1,xval = 0)
learn_ada <- ada(diagnosis~., data = train[,-1], test.x = train[,-c(1,2)], test.y = train$diagnosis, type = "gentle", control = control, iter = 70)
```

Testing the model.


```{r}
pre_ada <- predict(learn_ada, test[,-c(1,2)])
cm_ada <- confusionMatrix(pre_ada, test$diagnosis)
cm_ada
```

<br>

### ML 13: Support vector machines(SVM)

Training the model.

```{r}
# SVM 모델 학습
learn_svm <- svm(diagnosis ~ ., data = train[,-1])

```

Testing the model.

```{r}
# SVM 모델로 테스트 데이터 예측
pre_svm <- predict(learn_svm, test[,-c(1,2)])

# Confusion Matrix 계산
cm_svm <- confusionMatrix(pre_svm, test$diagnosis)

# Confusion Matrix 출력
cm_svm

```

<br>

### ML 14: Tunned Support vector machines

Training the model.

```{r}
# Hyperparameter 그리드 생성
gamma <- seq(0, 0.1, 0.005)
cost <- 2^(0:5)
parms <- expand.grid(cost = cost, gamma = gamma)

# 결과 저장 변수 초기화
acc_test <- numeric()
accuracy1 <- NULL
accuracy2 <- NULL

# 각각의 하이퍼파라미터에 대해 SVM 모델 학습 및 평가
for (i in 1:NROW(parms)) {
  learn_svm <- svm(diagnosis ~ ., data = train[,-1], gamma = parms$gamma[i], cost = parms$cost[i])
  pre_svm <- predict(learn_svm, test[,-c(1,2)])
  accuracy1 <- confusionMatrix(pre_svm, test$diagnosis)
  accuracy2[i] <- accuracy1$overall[1]
}

# 결과 데이터프레임 생성
acc <- data.frame(p = seq(1, NROW(parms)), cnt = accuracy2)

# 최적의 하이퍼파라미터 및 정확도 확인
opt_p <- subset(acc, cnt == max(cnt))[1,]
sub <- paste("Optimal number of parameters is", opt_p$p, "(accuracy:", opt_p$cnt, ") in SVM")

# 그래프 그리기
hchart(acc, 'line', hcaes(p, cnt)) %>%
  hc_title(text = "Accuracy With Varying Parameters (SVM)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Parameters")) %>%
  hc_yAxis(title = list(text = "Accuracy"))

```

```{r}
# Improved SVM 모델 학습
learn_imp_svm <- svm(diagnosis~., data=train[,-1], cost=parms$cost[opt_p$p], gamma=parms$gamma[opt_p$p])

```

Testing the model.

```{r}
# Improved SVM 모델을 사용하여 테스트 데이터에 대한 예측 수행
pre_imp_svm <- predict(learn_imp_svm, test[,-c(1,2)])

# Confusion Matrix 계산
cm_imp_svm <- confusionMatrix(pre_imp_svm, test$diagnosis)
cm_imp_svm

```

<br>

### ML 15: Random Forest: ranger

* 랜덤 포레스트 모델의 ranger 알고리즘을 사용
* 일반 랜덤 포레스트보다 빠르다고 함(정확한 내용은 모르겠음)

Training the model.

```{r}
# Random Forest 모델에 사용될 매개변수 그리드 정의
tgrid <- expand.grid(
  .mtry = 2:4,
  .splitrule = "gini",
  .min.node.size = c(10, 20)
)

# ranger를 사용한 Random Forest 모델 생성
ranger_caret <- train(
  diagnosis ~ .,                  # 종속 변수 및 독립 변수 설정
  data = train[, -1],             # 훈련 데이터 설정
  method = "ranger",              # 사용할 머신 러닝 알고리즘
  trControl = fitControl,         # 교차 검증 및 기타 제어 매개변수 설정
  tuneGrid = tgrid,               # 매개변수 그리드 설정
  num.trees = 100,                # 나무의 개수 설정
  importance = "permutation"      # 변수 중요도 계산 방법 설정
)

# 변수 중요도 계산
varImp(ranger_caret)

```

Testing the model.

```{r}
# Random Forest 모델을 사용하여 테스트 데이터에 대한 예측 수행
Rangercaret_pred <- predict(ranger_caret, test[,-c(1,2)])

# Confusion Matrix 계산
cm_Ranger <- confusionMatrix(Rangercaret_pred, test$diagnosis)
cm_Ranger

```

<br>

### ML 16: Random Forest: caret+RF

Training the model.

```{r}
# 10-fold 교차 검증을 3번 반복하는 제어 매개변수 설정
control <- trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=3)

# 모델 평가 지표로 사용할 Accuracy 설정
metric <- "Accuracy"

# 난수 생성기 시드 설정
set.seed(123)

# 랜덤 포레스트 모델의 mtry 매개변수 튜닝을 위한 매개변수 그리드 설정
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry)

# caret 패키지를 사용하여 랜덤 포레스트 모델 훈련
rf_caret <- train(diagnosis~.,data=train[,-1], 
                      method='rf', 
                      metric='Accuracy', 
                      tuneGrid=tunegrid, 
                      trControl=control)

# 변수 중요도 계산 및 출력
varImp(rf_caret)

```

Testing the model.

```{r}
RFcaret_pred<-predict(rf_caret,test[,-c(1,2)])
cm_rf<-confusionMatrix(RFcaret_pred,test$diagnosis)
cm_rf
```
<br>

## Step 9: The best model

이 커널에서는 여러 분류 ML 절차가 적용됨

##### Logistic Regression (로지스틱 회귀)
- **설명:** 로지스틱 회귀는 종속 변수가 이항인 경우 사용되는 통계 기법으로, 주로 이진 분류 문제에 적용됩니다. 확률 모델을 사용하여 각 클래스에 속할 확률을 예측합니다.
- **의미:** 종속 변수가 두 가지 범주 중 하나에 속하는 경우에 적합하며, 이를 통해 각 독립 변수의 영향을 평가할 수 있습니다.

##### Decision Tree (의사결정나무)
######## C5.0 및 improved C5.0
- **설명:** C5.0는 의사결정나무 알고리즘의 한 유형으로, 정보 이득을 최대화하여 데이터를 분할합니다. 개선된 C5.0는 C5.0의 성능을 향상시킨 버전입니다.
- **사용된 기법:** 정보 이득을 최대화하여 데이터를 잘게 나누어 각 분기에서의 예측 정확도를 높입니다.

##### Rpart와 Rpart pruned
- **설명:** Rpart는 의사결정나무 알고리즘으로, 나무를 성장시키고 가지치기를 통해 모델을 생성합니다. Pruned 옵션은 나무를 가지치기하여 과적합을 방지합니다.
- **사용된 기법:** 나무를 성장시키고, 필요에 따라 가지치기를 수행하여 모델을 생성합니다.

##### Naive Bayes (나이브 베이즈)
- **설명:** 나이브 베이즈는 베이즈 이론을 기반으로 하며, 각 독립 변수가 종속 변수에 미치는 영향을 독립적이라 가정합니다. 이는 계산의 단순성을 가져옵니다.
- **사용된 기법:** 독립 변수들 간의 조건부 독립 가정을 통해 베이즈 이론을 적용하여 클래스 확률을 계산합니다.

##### Random Forest (랜덤 포레스트)
######## a. ranger
- **설명:** Ranger는 랜덤 포레스트 모델의 한 구현체로, 여러 의사결정나무를 생성하고 각 나무의 예측을 결합하여 정확한 예측을 수행합니다.
- **사용된 기법:** 여러 의사결정나무를 병렬로 생성하고 예측을 결합하여 모델의 정확도를 향상시킵니다.

######## b. caret+ranger, caret+random forest
- **설명:** Caret 패키지를 활용하여 Ranger 및 Random Forest 모델을 훈련하고 최적의 매개변수를 찾아 모델의 정확도를 향상시킵니다.

##### K-nearest Neighbors (K-NN)
- **설명:** K-NN은 새로운 데이터 포인트와 가장 가까운 k개의 이웃을 찾아 다수결 투표를 통해 예측하는 알고리즘입니다.
- **사용된 기법:** 거리 측정 방법을 사용하여 가장 가까운 이웃을 찾아 예측합니다.

##### Classification Tree (분류 트리)
- **설명:** 분류 트리는 의사결정나무와 유사하지만 이진 분할을 사용하여 클래스를 예측하는 모델입니다.
- **사용된 기법:** 정보 이득이나 지니 불순도를 최소화하여 데이터를 분할하고 예측합니다.

##### Gradient Boosting Machine (GBM)
- **설명:** GBM은 여러 결정 트리를 순차적으로 학습하면서 이전 트리의 오차를 보정하여 모델을 개선합니다.
- **사용된 기법:** 이전 트리의 오차를 최소화하는 새로운 트리를 학습하여 모


<br>

```{r}
# 색상 벡터 설정
col <- c("#ed3b3b", "#0099ff")

# Logistic, C5.0, Tuned C5.0, RPart, Prune 시각화
par(mfrow=c(2,3))
fourfoldplot(cm_logistic$table, color = col, conf.level = 0, margin = 1, main=paste("로지스틱 (", round(cm_ranger$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_c50$table, color = col, conf.level = 0, margin = 1, main=paste("C5.0 (", round(cm_c50$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_imp_c50$table, color = col, conf.level = 0, margin = 1, main=paste("튜닝된 C5.0 (", round(cm_imp_c50$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_rp$table, color = col, conf.level = 0, margin = 1, main=paste("RPart (", round(cm_rp$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_pru$table, color = col, conf.level = 0, margin = 1, main=paste("가지치기 (", round(cm_pru$overall[1]*100), "%)", sep=""))

# CTree, NaiveBayes, K-nn, GBM, AdaBoost 시각화
par(mfrow=c(2,3))
fourfoldplot(cm_ct$table, color = col, conf.level = 0, margin = 1, main=paste("CTree (", round(cm_ct$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_nb$table, color = col, conf.level = 0, margin = 1, main=paste("나이브 베이즈 (", round(cm_nb$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_knn$table, color = col, conf.level = 0, margin = 1, main=paste("K-nn (", round(cm_ranger$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_gbm$table, color = col, conf.level = 0, margin = 1, main=paste("GBM (", round(cm_gbm$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_ada$table, color = col, conf.level = 0, margin = 1, main=paste("AdaBoost (", round(cm_ada$overall[1]*100), "%)", sep=""))

# SVM, Tuned SVM, RF, RF caret/ranger, RF caret/rf 시각화
par(mfrow=c(2,3))
fourfoldplot(cm_svm$table, color = col, conf.level = 0, margin = 1, main=paste("SVM (", round(cm_svm$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_imp_svm$table, color = col, conf.level = 0, margin = 1, main=paste("튜닝된 SVM (", round(cm_imp_svm$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_ranger$table, color = col, conf.level = 0, margin = 1, main=paste("RF (", round(cm_ranger$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_Ranger$table, color = col, conf.level = 0, margin = 1, main=paste("RF caret/ranger (", round(cm_ranger$overall[1]*100), "%)", sep=""))
fourfoldplot(cm_rf$table, color = col, conf.level = 0, margin = 1, main=paste("RF caret/rf (", round(cm_ranger$overall[1]*100), "%)", sep=""))


```

Which model is better?

```{r}
# 각 모델의 정확도 저장
opt_predict <- c(
  cm_logistic$overall[1],
  cm_ranger$overall[1],
  cm_Ranger$overall[1],
  cm_rf$overall[1],
  cm_c50$overall[1],
  cm_imp_c50$overall[1],
  cm_rp$overall[1],
  cm_pru$overall[1],
  cm_nb$overall[1],
  cm_ct$overall[1],
  cm_knn$overall[1],
  cm_gbm$overall[1],
  cm_ada$overall[1],
  cm_svm$overall[1],
  cm_imp_svm$overall[1]
)

# 모델 이름 설정
names(opt_predict) <- c(
  "Logistic regression",
  "Random Forest caret Ranger",
  "Random Forest Ranger",
  "Random Forest RF",
  "C5.0",
  "C5.0 improved",
  "Rpart",
  "Rpart improved",
  "Naive Bayes",
  "Classification tree",
  "K-nn",
  "GBM",
  "Adaboost",
  "SVM",
  "SVM improved"
)

# 가장 높은 정확도를 가진 모델 찾기
best_predict_model <- subset(opt_predict, opt_predict == max(opt_predict))
best_predict_model

```

```{r}
cm_imp_svm$table
```
<br>

## Step 10: Incorrectly classified 
잘못 분류된 환자에게는 무슨 일이 일어나는지

* 잘못 분류된 환자 필터링

```{r}
# 모델이 양성 종양('B')으로 잘못 예측하고 실제로는 악성 종양('M')인 환자들의 데이터를 확인
test[which(pre_imp_svm== 'B' & test$diagnosis=='M'),]
```

* 모든 변수의 평균 계산

```{r}
aggregate(breast_cancer_data[, 3:32], list(breast_cancer_data$diagnosis), mean)
```

* 출력값 해석
이 결과를 통해 각 변수의 평균값이 양성 종양과 악성 종양에서 어떻게 다르게 나타나는지 확인

예를 들어, radius_mean에서 양성 종양의 평균값이 낮고, 악성 종양의 평균값이 높다는 것을 알 수 있음 
이는 모델이 양성 종양을 악성 종양으로 잘못 분류한 경우에 대한 정보를 제공

<br>





